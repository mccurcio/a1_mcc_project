Data Mining
Practical Machine Learning
Tools and Techniques

Third Edition

Ian H. Witten

Copyright: 2011, Elsevier Inc.



# chapter 1

Extra box:
- Bias
Viewing generalization as a search in a space of possible concepts makes it clear that the
most important decisions in a machine learning system are:
  - The concept description language
  - The order in which the space is searched
  - The way that overfitting to the particular training data is avoided

These three properties are generally referred to as the bias of the search and are called:
- language bias, 
- search bias, and 
- overfitting-avoidance bias.


# CHAPTER 3  Output: Knowledge Representation

3.5  INSTANCE-BASED REPRESENTATION, p.78

- instance-based knowledge representation uses the instances themselves to represent what is learned
- In instance-based learning, all the real work is done when the time comes to classify a new instance rather than when the training set is processed. In a sense, then, the difference between this method and the others that we have seen is the time at which the “learning” takes place.

- In instance-based classification, each new instance is compared with existing ones using a distance metric, and the closest existing instance is used to assign the class to the new one. This is called the nearest-neighbor classification method.

- Generally, the standard Euclidean distance is used. However, this assumes that the attributes are normalized and are of equal importance.

- Problem: Deriving suitable attriute weights from the training set is a key problem.


# Chapter 7: Data Transformations, p.305

It is interesting to note 'robust techniques that are eminently
applicable to practical data mining problems.'


It good times you have enough data, but
in bad times you may need 10-fold cross-validation to obtain more relaible esttimates.  With tenfold cross-validation, this involves running
the learning scheme 100 times.

When assessing the performance of a learning scheme, any parameter tuning that goes on should be treated as though it were an integral part of the training process.

You must take care to not overfit the data thus be cautious of over-tuing parameters.


### In this chapter we examine six different ways in which the input can be massaged to make it more amenable for learning methods:

1. attribute selection 
   1. experiments show that adding useless attributes causes the performance of learning schemes such as decision trees and rules, linear regression, instance-based learners, and clustering methods to deteriorate.

2. attribute discretization
   1. Discretization of numeric attributes is absolutely essential if the task involves numeric attributes but the chosen learning scheme can only handle categorical ones.
   2. Using cateoricals for numerics and vice-versa.

3. data projections
   1. We also cover partial least-squares regression as a data projection technique for regression problems.
   2. Principal components analysis 
   3. random projections

4. sampling - an important step
   1. producing a random sample
   2. over-sampling ??
   3. under-sampling ??

5. data cleansing
   1. understanding the meaning of all the different attributes, 
   2. the conventions used in coding them, 
   3. the significance of missing values and duplicate data, 
   4. measurement noise, 
   5. typographical errors, and 
   6. the presence of systematic errors or 
   7. even deliberate ones
   8. Solutions include: automatic methods of cleansing data, of detecting outliers, and of spotting anomalies

6. converting multiclass problems to two-class ones
   1.



7.1  ATTRIBUTE SELECTION

There is always a diff between theory and practice...

p.308
Example: Experiments with a decision tree learner (C4.5) have shown that when adding a random binary attribute (generated by tossing an unbiased coin) to standard datasets impacts decision tree classification performance, causing it to deteriorate. The typically deterioration is on the order of 5 to 10% in the situations tested.

Explanation: As you proceed further down the tree, less and less data is available to help make the selection decision. At some point, with little data, the random attribute will look good just by chance.  Because the number of nodes at each level increases exponentially with depth, the chance of the rogue attribute looking good somewhere along the frontier multiplies up as the tree deepens.

Lesson: Divide-and-conquer tree learners and separate-and-conquer rule learners both suffer from this effect because they inexorably reduce the amount of data on which they base judgments.


p.308
#### Alternatively, **Naïve Bayes**, by contrast, does not fragment the instance space and robustly ignores irrelevant attributes.



