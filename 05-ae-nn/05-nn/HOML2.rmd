---
title: "HOML chapter 19"
author: "MCC"
date: "2/16/2020"
output: html_document
---

## Autoencoders

https://bradleyboehmke.github.io/HOML/autoencoders.html


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
```


```{r message=FALSE, warning=FALSE}
# Load Libraries
Libraries <- c("dplyr", "knitr", "ggplot2", "h2o")
for (p in Libraries) {  
    library(p, character.only = TRUE)
}
```

```{r}
mnist <- dslabs::read_mnist()
names(mnist)
```

```{r}
#h2o.no_progress()  # turn off progress bars
h2o.init(max_mem_size = "5g")  # initialize H2O instance
```

```{r}
# Convert mnist features to an h2o input data set
features <- as.h2o(mnist$train$images)

# Train an autoencoder
ae1 <- h2o.deeplearning(x = seq_along(features),
                        training_frame = features,
                        autoencoder = TRUE,
                        hidden = 2,
                        activation = 'Tanh',
                        sparse = TRUE
)

# Extract the deep features
ae1_codings <- h2o.deepfeatures(ae1, features, layer = 1)
ae1_codings
```

```{r}
# Hyperparameter search grid
hyper_grid <- list(hidden = list(c(50),
                                 c(100),
                                 c(300, 100, 300),
                                 c(100, 50, 100),
                                 c(250, 100, 50, 100, 250)))
```


```{r}
# Execute grid search
ae_grid <- h2o.grid(algorithm = 'deeplearning',
                    x = seq_along(features),
                    training_frame = features,
                    grid_id = 'autoencoder_grid',
                    autoencoder = TRUE,
                    activation = 'Tanh',
                    hyper_params = hyper_grid,
                    sparse = TRUE,
                    ignore_const_cols = FALSE,
                    seed = 123)

# Print grid details
h2o.getGrid('autoencoder_grid', sort_by = 'mse', decreasing = FALSE)
```


```{r}
# Get sampled test images
index <- sample(1:nrow(mnist$test$images), 4)
sampled_digits <- mnist$test$images[index, ]
colnames(sampled_digits) <- paste0("V", seq_len(ncol(sampled_digits)))

# Predict reconstructed pixel values
best_model_id <- ae_grid@model_ids[[1]]
best_model <- h2o.getModel(best_model_id)
reconstructed_digits <- predict(best_model, as.h2o(sampled_digits))
names(reconstructed_digits) <- paste0("V", seq_len(ncol(reconstructed_digits)))

combine <- rbind(sampled_digits, as.matrix(reconstructed_digits))

# Plot original versus reconstructed
par(mfrow = c(1, 3), mar=c(1, 1, 1, 1))
layout(matrix(seq_len(nrow(combine)), 4, 2, byrow = FALSE))
for(i in seq_len(nrow(combine))) {
    image(matrix(combine[i, ], 28, 28)[, 28:1], xaxt="n", yaxt="n")
}
```


```{r}
ae100_codings <- h2o.deepfeatures(best_model, features, layer = 1)
ae100_codings %>% as.data.frame() %>%
                  tidyr::gather() %>%
                  summarize(average_activation = mean(value))
```



```{r}
# Hyperparameter search grid
hyper_grid <- list(sparsity_beta = c(0.01, 0.05, 0.1, 0.2))

# Execute grid search
ae_sparsity_grid <- h2o.grid(algorithm = 'deeplearning',
                             x = seq_along(features),
                             training_frame = features,
                             grid_id = 'sparsity_grid',
                             autoencoder = TRUE,
                             hidden = 100,
                             activation = 'Tanh',
                             hyper_params = hyper_grid,
                             sparse = TRUE,
                             average_activation = -0.1,
                             ignore_const_cols = FALSE,
                             seed = 123)

# Print grid details
h2o.getGrid('sparsity_grid', sort_by = 'mse', decreasing = FALSE)
```















