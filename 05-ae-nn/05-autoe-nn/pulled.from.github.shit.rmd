---
title: "Building an autoencoder with R and keras"
output: html_notebook
---


```{r message=FALSE, warning=FALSE, include=FALSE}
# Load Libraries
Libraries <- c("ggplot2", "caret")
for (p in Libraries) {  
    library(p, character.only = TRUE)
}

library(keras)
install_keras()
```

https://raw.githubusercontent.com/lurd4862/Playing_with_autoencoders_keras/master/Building_an_autoencoder.Rmd

## What are autoencoders?

The main purpose of an encoder is to map high dimensional data into lower dimensional data while minimizing the loss of decoding accuracy.

How is that different from dimensionality reduction?

In it's simplest case the neural network can use basicly linear activation functions to approximate a PCA. The important thing is that it is an approximation.

Autoencoders are not unsupervised learning algorithms, instead they are self-learning algorithms since the network will try to replicate itself from lower dimensional space. In this sense the net will not really extract those features that are usefull to understand the data as much as it will extract the most important features to reproduce the data.

We can however perform dimensionality reduction if we redefine the loss function however:
[ipynb](https://github.com/kylemcdonald/Parametric-t-SNE/blob/master/Parametric%20t-SNE%20(Keras).ipynb)

In that great python notebook the author *kylemcdonald* defines a t-sne loss function in python and uses it to perform autoencoding via t-sne.

## How do we build them?

We can build one quite simply by defining the encoding layers and the decoding layers;

Initially people did this by defining a simple symmetrical neural network like this:

The initial half was responsible for encoding into lower dimensional space and the decoder was responible for mapping it back again to validate information loss.
In practice the network does not need to be symmetrical at all and can be more complicated such as having CNN layers for image encoding.

## Build it

OK, so let's show how the autoencoder is built by defining the encoder and decoder

### Step 1 - load and prepare the data

For the initial example we will use the iris dataset as our hello world showcase

#### Split test train

```{r}
split_ind <- iris$Species %>% caret::createDataPartition(p = 0.8,list = FALSE)

train <- iris[split_ind,]
test <- iris[-split_ind,]
```

#### Pre-process

Note, normally you would need to perform one-hot encoding for the classes but since we are not going to train the model to classify this isn't really needed...

```{r}
train_X <- train[, 1:4] %>% as.matrix()

train_y <- train[, 5] %>% keras::to_categorical()

test_X <- test[, 1:4] %>% as.matrix()

```

### Step 2 - define the encoder

It's the encoder's job to embed the data into lower dimensional space. So logically it should map from the initial input dimensions to the specified number of perceptrons in the output layer as new dimensions:

Notice that we define the different parts seperately because we are going to use the keras functional api instead in order to keep the individual models `encoder` and `decoder`

```{r}
# decoder <- keras::keras_model_sequential()

input_layer <-
    layer_input(shape = c(4))

encoder <-
    input_layer %>%
    layer_dense(units = 20, activation = "relu") %>%
    layer_dropout(rate = 0.2) %>%
    layer_dense(units = 10, activation = "relu") %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(units = 2) # 2 dimensions for the output layer

decoder <-
    encoder %>%
    layer_dense(units = 20, activation = "relu") %>%
    layer_dropout(rate = 0.2) %>%
    layer_dense(units = 10, activation = "relu") %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(units = 4) # 4 dimensions for the original 4 variables


```

### Step 3 - compile and train the encoder

To train the encoder we need to capture the initial input as our goal and back-propogate to best represent it
We treat this as a basic regression so we will use some arbitrary regression loss function (nothing fancy like t-sne)

    ```{r}
autoencoder_model <- keras_model(inputs = input_layer, outputs = decoder)

autoencoder_model %>% compile(loss = 'mean_squared_error',
                              optimizer = 'rmsprop',
                              metrics = c('accuracy'))

summary(autoencoder_model)
```

Now we train onto itself:

    ```{r}
history <- autoencoder_model %>% keras::fit(train_X,
                                            train_X,
                                            epochs = 200,
                                            shuffle = TRUE,
                                            validation_data = list(test_X, test_X))
```

The training seems to have gone pretty well:

    ```{r}
plot(history)
```

So now that we believe we have trained our encoder to embed the data into lower dimensional space, let's actually look at this data...

#### Visualize the embedding

First we can use the complete model to visualize the reproduced points vs the actual points

```{r}
reconstructed_points <- autoencoder_model %>% keras::predict_on_batch(x = train_X)

Viz_data <- dplyr::bind_rows(reconstructed_points %>%
                               tibble::as_tibble() %>%
                               setNames(names(train_X %>% tibble::as_tibble())) %>%
                               dplyr::mutate(data_origin = "reconstructed"),
                             train_X %>%
                               tibble::as_tibble() %>%
                               dplyr::mutate(data_origin = "original"))

# Viz_data %>%
#   ggplot(aes(Sepal.Length,Sepal.Width, color = data_origin))+
#   geom_point()

# Viz_data %>%
#   ggplot(aes(Petal.Length,Sepal.Width, color = data_origin))+
#   geom_point()

Viz_data %>% ggplot(aes(Petal.Length,Petal.Width, color = data_origin)) + geom_point()
```

