#### What is deep learning? {-}

By contrast a deep learning system is one that able to generalize information constructing multiple levels of representation or learning a hierarchy of features, ..., one  level at a time, using unsupervised feature learning to learn a new transformation at each level.[^110]

[^110]:Yoshua Bengio, Aaron Courville, and Pascal Vincent, Representation Learning: A Review and New Perspectives, arXiv:1206.5538v3, 23 Apr 2014

Another much simpler definition states, "What is not a multi-layer neural network is not deep learning - Anonymous."


-------------------

- "Probably approximately correct" learning theory by Leslie Valiant

----------------------------------------------

OVERFITTING HAS MANY FACES

- Bias and Variance
- One way to understand over-fitting is by decomposing generalization error into bias and variance. Bias is a learner’s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things irrespective of the real signal.

The bias-variance dilemma can be stated as follows.
• Models with too few parameters are inaccurate because of a large bias: they lack flexibility.
• Models with too many parameters are inaccurate because of a large variance: they are too sensitive to the sample
details (changes in the details will produce huge variations).
• Identifying the best model requires controlling the “model complexity”, i.e., the proper architecture and number
of parameters, to reach an appropriate compromise between bias and variance.

@book {
author = "Roberto Battiti and Mauro Brunato",
title = "The LION way. Machine Learning {\em plus} Intelligent Optimization",
publisher = "LIONlab, University of Trento, Italy",
year = "2017",
month = "December",
url = "http://intelligent-optimization.org/LIONbook/"
}








