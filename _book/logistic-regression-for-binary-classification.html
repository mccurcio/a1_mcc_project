<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Logistic Regression For Binary Classification | Comparison Of 6 Machine Learning Techniques Tested For Accuracy And FP/FN Using Myoglobin Proteins Vs. Control Set</title>
  <meta name="description" content="Six machine learning techniques are tested for accuracy and FP/FN using myoglobin &amp; control set." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Logistic Regression For Binary Classification | Comparison Of 6 Machine Learning Techniques Tested For Accuracy And FP/FN Using Myoglobin Proteins Vs. Control Set" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Six machine learning techniques are tested for accuracy and FP/FN using myoglobin &amp; control set." />
  <meta name="github-repo" content="mccurcio/sixml" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Logistic Regression For Binary Classification | Comparison Of 6 Machine Learning Techniques Tested For Accuracy And FP/FN Using Myoglobin Proteins Vs. Control Set" />
  
  <meta name="twitter:description" content="Six machine learning techniques are tested for accuracy and FP/FN using myoglobin &amp; control set." />
  

<meta name="author" content="Matthew C. Curcio" />


<meta name="date" content="2020-03-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="principle-component-analysis-of-a-binary-classification-system.html"/>
<link rel="next" href="neural-networks.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1</b> What is Machine Learning?</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#machine-learning-is"><i class="fa fa-check"></i><b>1.1</b> Machine Learning Is?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#what-is-predictive-modeling"><i class="fa fa-check"></i><b>1.1.1</b> What is Predictive Modeling?</a></li>
<li class="chapter" data-level="1.1.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#the-epicycle-of-analysis"><i class="fa fa-check"></i><b>1.1.2</b> The Epicycle of Analysis</a></li>
<li class="chapter" data-level="1.1.3" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#predictive-modeling"><i class="fa fa-check"></i><b>1.1.3</b> Predictive Modeling</a></li>
<li class="chapter" data-level="1.1.4" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>1.1.4</b> Supervised Learning</a></li>
<li class="chapter" data-level="1.1.5" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#unsupervised-learning"><i class="fa fa-check"></i><b>1.1.5</b> Unsupervised Learning</a></li>
<li class="chapter" data-level="1.1.6" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#five-challenges-in-predictive-modeling"><i class="fa fa-check"></i><b>1.1.6</b> Five Challenges In Predictive Modeling</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#research-description"><i class="fa fa-check"></i><b>1.2</b> Research Description</a><ul>
<li class="chapter" data-level="1.2.1" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>1.2.1</b> Exploratory Data Analysis (EDA)</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#caret-library-for-r"><i class="fa fa-check"></i><b>1.2.2</b> Caret library for R</a></li>
<li class="chapter" data-level="1.2.3" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#tuning-hyper-parameters"><i class="fa fa-check"></i><b>1.2.3</b> Tuning Hyper-parameters</a></li>
<li class="chapter" data-level="1.2.4" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#k-fold-cross-validation-of-results"><i class="fa fa-check"></i><b>1.2.4</b> K-Fold Cross validation of results</a></li>
<li class="chapter" data-level="1.2.5" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#train-command"><i class="fa fa-check"></i><b>1.2.5</b> Train command</a></li>
<li class="chapter" data-level="1.2.6" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html#analysis-of-results"><i class="fa fa-check"></i><b>1.2.6</b> Analysis of results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>2</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a><ul>
<li class="chapter" data-level="2.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#four-step-analysis"><i class="fa fa-check"></i><b>2.1.1</b> Four-Step Analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#useful-guides-for-exploratory-data-analysis"><i class="fa fa-check"></i><b>2.1.2</b> Useful Guides for Exploratory Data Analysis</a></li>
<li class="chapter" data-level="2.1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#questions-during-eda"><i class="fa fa-check"></i><b>2.1.3</b> Questions During EDA</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#analysis-of-raw-data"><i class="fa fa-check"></i><b>2.2</b> Analysis of RAW data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visually-inspect-raw-data-files"><i class="fa fa-check"></i><b>2.2.1</b> Visually inspect RAW data files</a></li>
<li class="chapter" data-level="2.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#inspect-raw-dataframe-structure-str"><i class="fa fa-check"></i><b>2.2.2</b> Inspect RAW dataframe structure, <code>str()</code></a></li>
<li class="chapter" data-level="2.2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-data-head-tail"><i class="fa fa-check"></i><b>2.2.3</b> Check RAW data <code>head</code> &amp; <code>tail</code></a></li>
<li class="chapter" data-level="2.2.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-data-types"><i class="fa fa-check"></i><b>2.2.4</b> Check RAW data types</a></li>
<li class="chapter" data-level="2.2.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-dataframe-dimensions"><i class="fa fa-check"></i><b>2.2.5</b> Check RAW dataframe dimensions</a></li>
<li class="chapter" data-level="2.2.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-for-missing-values"><i class="fa fa-check"></i><b>2.2.6</b> Check RAW for missing values</a></li>
<li class="chapter" data-level="2.2.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#number-of-polypeptides-per-class"><i class="fa fa-check"></i><b>2.2.7</b> Number of polypeptides per Class:</a></li>
<li class="chapter" data-level="2.2.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-summary-of-raw-data"><i class="fa fa-check"></i><b>2.2.8</b> Numerical summary of RAW data</a></li>
<li class="chapter" data-level="2.2.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visualize-descriptive-statistics-using-raw-data"><i class="fa fa-check"></i><b>2.2.9</b> Visualize Descriptive Statistics using RAW Data</a></li>
<li class="chapter" data-level="2.2.10" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-of-raw-data"><i class="fa fa-check"></i><b>2.2.10</b> Scatter plot of means of <em>Myoglobin-Control</em> amino acid composition of RAW Data</a></li>
<li class="chapter" data-level="2.2.11" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#means-of-percent-amino-acid-composition-of-control-myoglobin-categories-raw-data"><i class="fa fa-check"></i><b>2.2.11</b> Means of percent amino acid composition of control &amp; myoglobin categories, RAW data</a></li>
<li class="chapter" data-level="2.2.12" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-grand-means-of-overall-amino-acid-composition-raw-data"><i class="fa fa-check"></i><b>2.2.12</b> Boxplots of grand-means of overall amino acid composition, RAW data</a></li>
<li class="chapter" data-level="2.2.13" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-control-only-raw-data"><i class="fa fa-check"></i><b>2.2.13</b> Boxplots of amino acid compositions for control (only), RAW data</a></li>
<li class="chapter" data-level="2.2.14" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-myoglobin-only-raw-data"><i class="fa fa-check"></i><b>2.2.14</b> Boxplots of amino acid compositions for myoglobin (only), RAW data</a></li>
<li class="chapter" data-level="2.2.15" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-length-of-polypeptides-for-raw-data"><i class="fa fa-check"></i><b>2.2.15</b> Boxplots Of Length Of Polypeptides For RAW Data</a></li>
<li class="chapter" data-level="2.2.16" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-coefficient-of-variance-for-raw-data"><i class="fa fa-check"></i><b>2.2.16</b> Plot Coefficient Of Variance For RAW Data</a></li>
<li class="chapter" data-level="2.2.17" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#skewness-of-distributions-raw-data"><i class="fa fa-check"></i><b>2.2.17</b> Skewness of distributions, RAW data</a></li>
<li class="chapter" data-level="2.2.18" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#qq-plots-of-20-amino-acids-raw-data"><i class="fa fa-check"></i><b>2.2.18</b> QQ-Plots of 20 amino acids, RAW data</a></li>
<li class="chapter" data-level="2.2.19" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#determine-coefficients-of-correlation-raw-data"><i class="fa fa-check"></i><b>2.2.19</b> Determine coefficients of correlation, RAW data</a></li>
<li class="chapter" data-level="2.2.20" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#how-to-dimension-reduction-using-high-correlation"><i class="fa fa-check"></i><b>2.2.20</b> How to: Dimension Reduction using High Correlation</a></li>
<li class="chapter" data-level="2.2.21" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boruta-random-forest-test-raw-data"><i class="fa fa-check"></i><b>2.2.21</b> Boruta Random Forest Test, RAW data</a></li>
<li class="chapter" data-level="2.2.22" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-variable-importance-raw-data"><i class="fa fa-check"></i><b>2.2.22</b> Plot variable importance, RAW Data</a></li>
<li class="chapter" data-level="2.2.23" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#variable-importance-scores-raw-data"><i class="fa fa-check"></i><b>2.2.23</b> Variable importance scores, RAW Data</a></li>
<li class="chapter" data-level="2.2.24" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#conclusion-for-boruta-random-forest-test-raw-data"><i class="fa fa-check"></i><b>2.2.24</b> Conclusion for Boruta random forest test, RAW Data</a></li>
<li class="chapter" data-level="2.2.25" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#conclusions-for-eda-raw-data"><i class="fa fa-check"></i><b>2.2.25</b> Conclusions For EDA, RAW data</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#analysis-of-transformed-data"><i class="fa fa-check"></i><b>2.3</b> Analysis of TRANSFORMED data</a><ul>
<li class="chapter" data-level="2.3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-transformed-dataframe-dimensions"><i class="fa fa-check"></i><b>2.3.1</b> Check Transformed dataframe dimensions</a></li>
<li class="chapter" data-level="2.3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-transformed-for-missing-values"><i class="fa fa-check"></i><b>2.3.2</b> Check Transformed for missing values</a></li>
<li class="chapter" data-level="2.3.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#count-transformed-data-for-the-number-of-polypeptides-per-class"><i class="fa fa-check"></i><b>2.3.3</b> Count Transformed data for the number of polypeptides per class</a></li>
<li class="chapter" data-level="2.3.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visualization-descriptive-statistics-transformed-data"><i class="fa fa-check"></i><b>2.3.4</b> Visualization Descriptive Statistics, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-sqrt-x_i-transformed-data"><i class="fa fa-check"></i><b>2.3.5</b> Scatter plot of means of <em>Myoglobin-Control</em> amino acid composition <span class="math inline">\(\sqrt x_i\)</span>, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#grouped-bar-chart-of-means-for-percent-amino-acid-composition-of-transformed-data-control-myoglobin-categories"><i class="fa fa-check"></i><b>2.3.6</b> Grouped bar chart of means for percent amino acid composition of Transformed Data; control &amp; myoglobin categories</a></li>
<li class="chapter" data-level="2.3.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-grand-means-of-the-overall-amino-acid-composition-of-square-root-transformed-data"><i class="fa fa-check"></i><b>2.3.7</b> Boxplots of grand-means of the overall amino acid composition of square-root transformed data</a></li>
<li class="chapter" data-level="2.3.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-control-only-of-square-root-transformed-data"><i class="fa fa-check"></i><b>2.3.8</b> Boxplots of amino acid compositions for control (only) of square-root transformed data</a></li>
<li class="chapter" data-level="2.3.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-myoglobin-of-square-root-transformed-dataonly-transformed-data"><i class="fa fa-check"></i><b>2.3.9</b> Boxplots of amino acid compositions for myoglobin of square-root transformed Data(only), TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.10" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-length-of-polypeptides-of-transformed-data-myoglobin-control-combined"><i class="fa fa-check"></i><b>2.3.10</b> Boxplots Of Length Of Polypeptides Of Transformed Data; Myoglobin, Control &amp; Combined</a></li>
<li class="chapter" data-level="2.3.11" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#coefficient-of-variance-cv-transformed-data"><i class="fa fa-check"></i><b>2.3.11</b> Coefficient of Variance (CV), TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.12" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-of-coefficient-of-variance-cv"><i class="fa fa-check"></i><b>2.3.12</b> Plot of Coefficient Of Variance (CV)</a></li>
<li class="chapter" data-level="2.3.13" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#skewness-of-distributions-transformed-data"><i class="fa fa-check"></i><b>2.3.13</b> Skewness of distributions, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.14" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#qq-plots-of-20-amino-acids-transformed-data"><i class="fa fa-check"></i><b>2.3.14</b> QQ Plots of 20 amino acids, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.15" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#determine-coefficients-of-correlation-transformed-data"><i class="fa fa-check"></i><b>2.3.15</b> Determine coefficients of correlation, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.16" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boruta---dimensionality-reduction-transformed-data"><i class="fa fa-check"></i><b>2.3.16</b> Boruta - Dimensionality Reduction, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.17" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-variable-importance-transformed-data"><i class="fa fa-check"></i><b>2.3.17</b> Plot Variable Importance, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.18" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#variable-importance-scores-transformed-data"><i class="fa fa-check"></i><b>2.3.18</b> Variable Importance Scores, TRANSFORMED data</a></li>
<li class="chapter" data-level="2.3.19" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#eda-results"><i class="fa fa-check"></i><b>2.3.19</b> EDA Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html"><i class="fa fa-check"></i><b>3</b> Principle Component Analysis of A Binary Classification System</a><ul>
<li class="chapter" data-level="3.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#data-centering-scaling-normalization"><i class="fa fa-check"></i><b>3.2</b> Data centering / scaling / normalization</a><ul>
<li class="chapter" data-level="3.2.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#histograms-of-scaled-vs.-unscaled-data"><i class="fa fa-check"></i><b>3.2.1</b> Histograms of Scaled Vs. Unscaled data</a></li>
<li class="chapter" data-level="3.2.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#finding-the-covariance-matrix"><i class="fa fa-check"></i><b>3.2.2</b> Finding the Covariance Matrix</a></li>
<li class="chapter" data-level="" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#covariance-of-two-variables"><i class="fa fa-check"></i>Covariance of two variables</a></li>
<li class="chapter" data-level="" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#covariance-of-matrices"><i class="fa fa-check"></i>Covariance of matrices</a></li>
<li class="chapter" data-level="3.2.3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#finding-pca-via-singular-value-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Finding PCA via singular value decomposition</a></li>
<li class="chapter" data-level="3.2.4" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#example-of-two-dimensional-pca-using-random-data"><i class="fa fa-check"></i><b>3.2.4</b> Example of two-dimensional PCA using random data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#principle-component-analysis-using-norm_c_m_20aa"><i class="fa fa-check"></i><b>3.3</b> Principle component analysis using <code>norm_c_m_20aa</code></a></li>
<li class="chapter" data-level="3.4" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#screeplot-cumulative-proportion-of-variance-plot"><i class="fa fa-check"></i><b>3.4</b> Screeplot &amp; Cumulative Proportion of Variance plot</a></li>
<li class="chapter" data-level="3.5" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#biplots"><i class="fa fa-check"></i><b>3.5</b> Biplots</a><ul>
<li class="chapter" data-level="3.5.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#biplot-1-pc1-vs.-pc2-with-class-by-color-labels"><i class="fa fa-check"></i><b>3.5.1</b> Biplot 1: PC1 Vs. PC2 with ‘Class’ by color labels</a></li>
<li class="chapter" data-level="3.5.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#biplot-2-determination-of-4-rule-set-for-outliers"><i class="fa fa-check"></i><b>3.5.2</b> Biplot 2: Determination Of 4 Rule Set For Outliers</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#obtain-anomalous-points-from-biplot-2-pc1-vs.-pc2"><i class="fa fa-check"></i><b>3.6</b> Obtain Anomalous Points From Biplot #2: PC1 Vs. PC2</a><ul>
<li class="chapter" data-level="3.6.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#outliers-from-principal-component-1"><i class="fa fa-check"></i><b>3.6.1</b> Outliers from Principal Component-1</a></li>
<li class="chapter" data-level="3.6.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#outliers-from-principal-component-2"><i class="fa fa-check"></i><b>3.6.2</b> Outliers from Principal Component-2</a></li>
<li class="chapter" data-level="3.6.3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#list-of-all-outliers-union-and-sorted-found-using-the-ruleset-1-through-4"><i class="fa fa-check"></i><b>3.6.3</b> List of all outliers (union and sorted) found using the ruleset 1 through 4</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#pca-results"><i class="fa fa-check"></i><b>3.7</b> PCA Results</a><ul>
<li class="chapter" data-level="3.7.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#outliers-derived-from-pc1-vs-pc2"><i class="fa fa-check"></i><b>3.7.1</b> Outliers derived from PC1 Vs PC2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html"><i class="fa fa-check"></i><b>4</b> Logistic Regression For Binary Classification</a><ul>
<li class="chapter" data-level="4.1" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-training-1-using-20-features"><i class="fa fa-check"></i><b>4.2</b> Logit Training #1 Using 20 Features</a></li>
<li class="chapter" data-level="4.3" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-results-1"><i class="fa fa-check"></i><b>4.3</b> Logit Results #1</a></li>
<li class="chapter" data-level="4.4" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-training-2-using-9-features"><i class="fa fa-check"></i><b>4.4</b> Logit Training #2 Using 9 Features</a><ul>
<li class="chapter" data-level="4.4.1" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-training-2-using-9-features-1"><i class="fa fa-check"></i><b>4.4.1</b> Logit Training #2 Using 9 Features</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-summary-2"><i class="fa fa-check"></i><b>4.5</b> Logit Summary #2</a></li>
<li class="chapter" data-level="4.6" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-confusion-matrix-2"><i class="fa fa-check"></i><b>4.6</b> Logit Confusion Matrix #2</a></li>
<li class="chapter" data-level="4.7" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#obtain-list-of-false-positives-false-negatives"><i class="fa fa-check"></i><b>4.7</b> Obtain List of False Positives &amp; False Negatives</a></li>
<li class="chapter" data-level="4.8" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-results"><i class="fa fa-check"></i><b>4.8</b> Logit Results</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>5</b> Neural Networks</a><ul>
<li class="chapter" data-level="5.1" data-path="neural-networks.html"><a href="neural-networks.html#introduction-3"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="neural-networks.html"><a href="neural-networks.html#the-one-neuron-system"><i class="fa fa-check"></i><b>5.2</b> The One Neuron System</a><ul>
<li class="chapter" data-level="5.2.1" data-path="neural-networks.html"><a href="neural-networks.html#summation-function"><i class="fa fa-check"></i><b>5.2.1</b> Summation Function</a></li>
<li class="chapter" data-level="5.2.2" data-path="neural-networks.html"><a href="neural-networks.html#activation-functions"><i class="fa fa-check"></i><b>5.2.2</b> Activation Functions</a></li>
<li class="chapter" data-level="5.2.3" data-path="neural-networks.html"><a href="neural-networks.html#binary-output-or-probability"><i class="fa fa-check"></i><b>5.2.3</b> Binary Output Or Probability</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="neural-networks.html"><a href="neural-networks.html#the-two-neuron-system"><i class="fa fa-check"></i><b>5.3</b> The Two Neuron System</a><ul>
<li class="chapter" data-level="5.3.1" data-path="neural-networks.html"><a href="neural-networks.html#feed-forward-in-a-two-neuron-network"><i class="fa fa-check"></i><b>5.3.1</b> Feed-Forward In A Two Neuron Network</a></li>
<li class="chapter" data-level="5.3.2" data-path="neural-networks.html"><a href="neural-networks.html#error-back-propagation"><i class="fa fa-check"></i><b>5.3.2</b> Error Back-propagation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="neural-networks.html"><a href="neural-networks.html#neural-network-experiment-for-binary-classification"><i class="fa fa-check"></i><b>5.4</b> Neural Network Experiment For Binary Classification</a><ul>
<li class="chapter" data-level="5.4.1" data-path="neural-networks.html"><a href="neural-networks.html#train-model-with-neural-networks"><i class="fa fa-check"></i><b>5.4.1</b> Train model with neural networks</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="neural-networks.html"><a href="neural-networks.html#neural-network-results"><i class="fa fa-check"></i><b>5.5</b> Neural Network Results</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html"><i class="fa fa-check"></i><b>6</b> Support Vector Machines for Binary Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#introduction-4"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#linearly-separable"><i class="fa fa-check"></i><b>6.2</b> Linearly Separable</a></li>
<li class="chapter" data-level="6.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#understanding-the-hyperplane-equation"><i class="fa fa-check"></i><b>6.3</b> Understanding the hyperplane equation</a></li>
<li class="chapter" data-level="6.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#soft-margins"><i class="fa fa-check"></i><b>6.4</b> Soft Margins</a><ul>
<li class="chapter" data-level="6.4.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#linear-kx-y-wt-x-b"><i class="fa fa-check"></i><b>6.4.1</b> Linear: <span class="math inline">\(K(x, ~y) ~=~ w^T x + b\)</span></a></li>
<li class="chapter" data-level="6.4.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#polynomial-kx_i-y-gamma-x_it-x_j-rlarge-d-gamma-0"><i class="fa fa-check"></i><b>6.4.2</b> Polynomial: <span class="math inline">\(K(x_i, ~y) ~=~ ( \gamma ~x_i^T ~x_j ~+~ r)^{\Large d}, ~~ \gamma &gt; 0\)</span></a></li>
<li class="chapter" data-level="6.4.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#radial-basis-function-rbf-kx_i-x_j-exp---gamma-parallel-x_it---x_j-parallel-2-gamma-0"><i class="fa fa-check"></i><b>6.4.3</b> Radial Basis Function (RBF): <span class="math inline">\(K(x_i, x_j) ~=~ exp ( - {\gamma} \parallel x_i^T - x_j \parallel ^2 ), ~~ \gamma &gt;0\)</span></a></li>
<li class="chapter" data-level="6.4.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#sigmoidal-kx-y-tanh-gamma-xt-y-r-gamma-0"><i class="fa fa-check"></i><b>6.4.4</b> Sigmoidal: <span class="math inline">\(K(x, y) ~=~ {\tanh} (\gamma~ x^T ~ y ~+~ r ), ~~ \gamma &gt;0\)</span></a></li>
<li class="chapter" data-level="6.4.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear"><i class="fa fa-check"></i><b>6.4.5</b> SVM-Linear</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-with-no-kernel"><i class="fa fa-check"></i><b>6.5</b> SVM-Linear with No Kernel</a><ul>
<li class="chapter" data-level="6.5.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-training"><i class="fa fa-check"></i><b>6.5.1</b> SVM-Linear Training</a></li>
<li class="chapter" data-level="6.5.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-model-summary"><i class="fa fa-check"></i><b>6.5.2</b> SVM-Linear Model Summary</a></li>
<li class="chapter" data-level="6.5.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-predict-test_set"><i class="fa fa-check"></i><b>6.5.3</b> SVM-Linear Predict test_set</a></li>
<li class="chapter" data-level="6.5.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-confusion-matrix"><i class="fa fa-check"></i><b>6.5.4</b> SVM-Linear Confusion Matrix</a></li>
<li class="chapter" data-level="6.5.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-obtain-false-positives-false-negatives"><i class="fa fa-check"></i><b>6.5.5</b> SVM-Linear Obtain False Positives &amp; False Negatives</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-model"><i class="fa fa-check"></i><b>6.6</b> SVM-Poly Model</a></li>
<li class="chapter" data-level="6.7" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-training"><i class="fa fa-check"></i><b>6.7</b> SVM-Poly Training</a></li>
<li class="chapter" data-level="6.8" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-model-summary"><i class="fa fa-check"></i><b>6.8</b> SVM-Poly Model Summary</a></li>
<li class="chapter" data-level="6.9" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-predict-test_set"><i class="fa fa-check"></i><b>6.9</b> SVM-Poly Predict test_set</a></li>
<li class="chapter" data-level="6.10" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-confusion-matrix"><i class="fa fa-check"></i><b>6.10</b> SVM-Poly Confusion Matrix</a></li>
<li class="chapter" data-level="6.11" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-obtain-false-positives-false-negatives"><i class="fa fa-check"></i><b>6.11</b> SVM-Poly Obtain False Positives &amp; False Negatives</a></li>
<li class="chapter" data-level="6.12" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#introduction-5"><i class="fa fa-check"></i><b>6.12</b> Introduction</a></li>
<li class="chapter" data-level="6.13" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-training"><i class="fa fa-check"></i><b>6.13</b> SVM-RBF Training</a></li>
<li class="chapter" data-level="6.14" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-model-summary"><i class="fa fa-check"></i><b>6.14</b> SVM-RBF Model Summary</a></li>
<li class="chapter" data-level="6.15" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-predict-test_set"><i class="fa fa-check"></i><b>6.15</b> SVM-RBF Predict test_set</a></li>
<li class="chapter" data-level="6.16" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-confusion-matrix"><i class="fa fa-check"></i><b>6.16</b> SVM-RBF Confusion Matrix</a></li>
<li class="chapter" data-level="6.17" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-obtain-false-positives-false-negatives"><i class="fa fa-check"></i><b>6.17</b> SVM-RBF Obtain False Positives &amp; False Negatives</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>7</b> Results</a><ul>
<li class="chapter" data-level="" data-path="results.html"><a href="results.html#scatter-plots-of-anomalies-vs.-fp-fn-outputs"><i class="fa fa-check"></i>Scatter Plots of Anomalies Vs. FP &amp; FN Outputs</a><ul>
<li class="chapter" data-level="7.0.1" data-path="results.html"><a href="results.html#pca-anomalies-plot"><i class="fa fa-check"></i><b>7.0.1</b> PCA-Anomalies Plot</a></li>
<li class="chapter" data-level="7.0.2" data-path="results.html"><a href="results.html#logit-plot"><i class="fa fa-check"></i><b>7.0.2</b> Logit Plot</a></li>
<li class="chapter" data-level="7.0.3" data-path="results.html"><a href="results.html#svm-linear-plot"><i class="fa fa-check"></i><b>7.0.3</b> SVM-Linear Plot</a></li>
<li class="chapter" data-level="7.0.4" data-path="results.html"><a href="results.html#svm-polynomial-plot"><i class="fa fa-check"></i><b>7.0.4</b> SVM-Polynomial Plot</a></li>
<li class="chapter" data-level="7.0.5" data-path="results.html"><a href="results.html#svm-radial-basis-function-plot"><i class="fa fa-check"></i><b>7.0.5</b> SVM-Radial Basis Function Plot</a></li>
<li class="chapter" data-level="7.0.6" data-path="results.html"><a href="results.html#neural-network-function-plot"><i class="fa fa-check"></i><b>7.0.6</b> Neural Network Function Plot</a></li>
<li class="chapter" data-level="7.0.7" data-path="results.html"><a href="results.html#statistical-learning-method-vs-total-number-of-fpfn"><i class="fa fa-check"></i><b>7.0.7</b> Statistical Learning Method Vs Total Number of FP/FN</a></li>
</ul></li>
<li class="chapter" data-level="7.1" data-path="results.html"><a href="results.html#comparison-of-machine-learning-accuracies"><i class="fa fa-check"></i><b>7.1</b> Comparison of Machine Learning Accuracies</a><ul>
<li class="chapter" data-level="7.1.1" data-path="results.html"><a href="results.html#plot-the-resamples-output-to-compare-the-models."><i class="fa fa-check"></i><b>7.1.1</b> Plot the resamples output to compare the models.</a></li>
<li class="chapter" data-level="7.1.2" data-path="results.html"><a href="results.html#mean-accuracies-of-m.l.-techniques-n10"><i class="fa fa-check"></i><b>7.1.2</b> Mean Accuracies of M.L. Techniques, n=10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>8</b> Conclusion</a><ul>
<li class="chapter" data-level="8.1" data-path="conclusion.html"><a href="conclusion.html#comparison-of-pca-anomalies"><i class="fa fa-check"></i><b>8.1</b> Comparison of PCA Anomalies</a></li>
<li class="chapter" data-level="8.2" data-path="conclusion.html"><a href="conclusion.html#comparison-of-accuracy-measurements"><i class="fa fa-check"></i><b>8.2</b> Comparison of Accuracy Measurements</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>9</b> Appendices</a><ul>
<li class="chapter" data-level="9.1" data-path="appendices.html"><a href="appendices.html#install-r-rstudio"><i class="fa fa-check"></i><b>9.1</b> Install R &amp; RStudio</a></li>
<li class="chapter" data-level="9.2" data-path="appendices.html"><a href="appendices.html#load-libraries-used-in-this-project"><i class="fa fa-check"></i><b>9.2</b> Load Libraries Used In This Project</a></li>
<li class="chapter" data-level="9.3" data-path="appendices.html"><a href="appendices.html#calculate-the-amino-acid-compositions-aac-and-di-peptide-compositions-dpc"><i class="fa fa-check"></i><b>9.3</b> Calculate the amino acid compositions (AAC) and Di-peptide compositions (DPC)</a></li>
<li class="chapter" data-level="9.4" data-path="appendices.html"><a href="appendices.html#calculate-aac-and-dpc-values-function"><i class="fa fa-check"></i><b>9.4</b> Calculate AAC and DPC values function</a></li>
<li class="chapter" data-level="9.5" data-path="appendices.html"><a href="appendices.html#run-myoglobin"><i class="fa fa-check"></i><b>9.5</b> Run Myoglobin</a></li>
<li class="chapter" data-level="9.6" data-path="appendices.html"><a href="appendices.html#run-control-human-not-myoglobin"><i class="fa fa-check"></i><b>9.6</b> Run Control / Human-NOT-myoglobin</a></li>
<li class="chapter" data-level="9.7" data-path="appendices.html"><a href="appendices.html#run-controls"><i class="fa fa-check"></i><b>9.7</b> Run Controls</a></li>
<li class="chapter" data-level="9.8" data-path="appendices.html"><a href="appendices.html#keep-aac-only-for-raw-data"><i class="fa fa-check"></i><b>9.8</b> KEEP AAC ONLY FOR RAW DATA</a></li>
<li class="chapter" data-level="9.9" data-path="appendices.html"><a href="appendices.html#transform-c-f-i-from-c_m_raw_aac"><i class="fa fa-check"></i><b>9.9</b> Transform {C, F, I} from c_m_RAW_AAC</a></li>
<li class="chapter" data-level="9.10" data-path="appendices.html"><a href="appendices.html#where-to-find-help"><i class="fa fa-check"></i><b>9.10</b> Where To Find Help</a></li>
<li class="chapter" data-level="9.11" data-path="appendices.html"><a href="appendices.html#machine-setting-session-info"><i class="fa fa-check"></i><b>9.11</b> Machine Setting &amp; Session Info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Comparison Of 6 Machine Learning Techniques Tested For Accuracy And FP/FN Using Myoglobin Proteins Vs. Control Set</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression-for-binary-classification" class="section level1">
<h1><span class="header-section-number">4</span> Logistic Regression For Binary Classification</h1>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>For individuals who have studied cell biology or biochemistry, logistic regression may be familiar as dose-response curves, enzyme kinetic curves, sigmoidal curves, median lethal dose curve (LD-50) or even an exponential growth curve given limited resources.</p>
<p>However, in the context of predictive modeling, Logistic Regression is used as a binary classifier that toggle between the logical values of zero or one.</p>
<p>Logistic regression (Logit) derives its name from its similarity to linear regression, as we shall see below. The input/independent variable for Logit is the set of real numbers, (<span class="math inline">\(X ~ \in ~ \Re\)</span>). While, the output of a Logistic Regression is not represented by {0, 1}, (<span class="math inline">\(Y ~ \notin ~ \Re\)</span>),</p>
<p><span class="math display">\[\begin{equation}
f(x) = ~~ \left \{ \begin{matrix} 0 ~~for~~ x &lt; 0 \\ 1 ~~for~~ x \geq 0 \end{matrix} \right.
\end{equation}\]</span></p>
<p>Using Logistic Regression, we may calculate the presence or absence of a product or quality that we wish to model given a difficult situation where the transition is not clear.</p>
<p>In the figure below, the function’s domain, <span class="math inline">\(X \in \{-\infty\)</span> to <span class="math inline">\(\infty\}\)</span>, whereby its range is {0, 1}. In the figure, the <em>decision boundary</em> is <span class="math inline">\(x ~=\)</span> 0, denoted by the <em>red dotted line</em>. At the inflection point the curves range changes from <em>zero</em>, absence, to <em>one</em>, the presence of quality or item.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The logistic growth curve is commonly denoted by:</p>
<p><span class="math display">\[\begin{equation}
f(x) ~=~ \frac{M}{1 + Ae^{-r(x - x_0)}}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(M\)</span> is the curve’s maximum value, <span class="math inline">\(r\)</span> is the maximum growth rate (also called the Malthusian parameter <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>), <span class="math inline">\(x_0\)</span> is the midpoint of the curve, <span class="math inline">\(A\)</span> is the number of times that the initial population must double to reach <span class="math inline">\(M\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>In the specific case of <em>Logistic Regression for Binary Classification</em> where we have a probability between 0 and 1, <span class="math inline">\(M\)</span>, and <span class="math inline">\(A\)</span> take on the value one.</p>
<p><span class="math display">\[\begin{equation}
f(x) ~=~ \frac{1}{1 + e^{-(WX+b)}}
\end{equation}\]</span></p>
<p>Since the logistic equation is exponential, it is easier to work with the formula in terms of its odds or <em>log-odds</em>. Odds are the probabilities of success over failure denoted as <span class="math inline">\(\Large \frac{p}{1-p}\)</span> or more precisely log-odds as <span class="math inline">\(\large ln \left (\frac{p}{1-p} \right )\)</span>.</p>
<p>Simply by using log-odds, logistic regression may be more easily expressed as a set of linear equations in x.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Hence we can now go from linear regression to logistic regression.</p>
<p><span class="math display">\[\begin{equation}
ln ~ \left ( \frac{Pr(y_i ~=~ 1|x_i)}{Pr(y_i ~=~ 0|x_i)} \right ) =~ \beta_0 + \beta_1 x_1 +~ ... ~+ \beta_{n} x_{n}
\end{equation}\]</span></p>
<p>Substitute (<span class="math inline">\(p\)</span> for <span class="math inline">\(Pr(y_i ~=~ 1|x_i)\)</span>) and (<span class="math inline">\(1-p\)</span> for <span class="math inline">\(Pr(y_i ~=~ 0|x_i)\)</span>) and change notation to summation on the right hand side:</p>
<p><span class="math display">\[\begin{equation}
ln \left( \frac {p}{1-p} \right) =~ \sum_i^{k} \beta_i x_i
\end{equation}\]</span></p>
<p>Eliminate the natural log by taking the exponent on both sides:</p>
<p><span class="math display">\[\begin{equation}
\frac {p}{1-p} =~ exp \left ( \sum_i^{k} \beta_i x_i \right )
\end{equation}\]</span></p>
<p>Substitute <span class="math inline">\(u = \sum_i^{k} \beta_i x_i\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\frac {p}{1-p} =~ e^u
\end{equation}\]</span></p>
<p>Rearrange to solve for <span class="math inline">\(\large p\)</span>:</p>
<p><span class="math display">\[\begin{equation}
p(u) ~=~ \frac{e^u}{1 + e^u}
\end{equation}\]</span></p>
<p>Take the derivative of both sides using quotient rule:</p>
<p><span class="math display">\[\begin{equation}
p&#39;(u) ~=~ \frac {(e^u)(1 + e^u) - (e^u)(e^u)}{(1 + e^u)^2}
\end{equation}\]</span></p>
<p>Simplify:</p>
<p><span class="math display">\[\begin{equation}
p&#39;(u) ~=~ \frac {e^u}{(1 + e^u)^2}
\end{equation}\]</span></p>
<p>Separate out to produce two fractions:</p>
<p><span class="math display">\[\begin{equation}
p&#39;(u) ~=~ \left ( \frac {e^u}{1 + e^u} \right ) \cdot \left ( \frac{1}{1 + e^u} \right )
\end{equation}\]</span></p>
<p>Substitute our previous success and failure variables back into place:</p>
<p><span class="math display">\[\begin{equation}
p&#39;(u) ~=~ p(u) \cdot ( 1 - p(u))
\end{equation}\]</span></p>
<hr />
<p>Now we can calculate the probabilities as well as the values for any given x value.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># Load Libraries</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2">Libraries &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;doMC&quot;</span>, <span class="st">&quot;knitr&quot;</span>, <span class="st">&quot;readr&quot;</span>, <span class="st">&quot;tidyverse&quot;</span>, <span class="st">&quot;caret&quot;</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="cf">for</span> (p <span class="cf">in</span> Libraries) { </a>
<a class="sourceLine" id="cb1-4" data-line-number="4">    <span class="kw">library</span>(p, <span class="dt">character.only =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5">}</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Import relevant data</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">c_m_TRANSFORMED &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;./00-data/02-aac_dpc_values/c_m_TRANSFORMED.csv&quot;</span>,</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">                            <span class="dt">col_types =</span> <span class="kw">cols</span>(<span class="dt">Class =</span> <span class="kw">col_factor</span>(<span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0&quot;</span>, <span class="st">&quot;1&quot;</span>)),</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">                                             <span class="dt">PID =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">                                             <span class="dt">TotalAA =</span> <span class="kw">col_skip</span>()))</a></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># Partition data into training and testing sets</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(c_m_TRANSFORMED<span class="op">$</span>Class, <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">training_set<span class="fl">.1</span> &lt;-<span class="st"> </span>c_m_TRANSFORMED[index, ]</a></code></pre></div>
<p>The <code>test.set.1</code> and <code>Class.test</code> data sets are not produced since the Logit run with 20 features was not deemed useful. The reason for its dismissal was that is contained extraneous features.</p>
</div>
<div id="logit-training-1-using-20-features" class="section level2">
<h2><span class="header-section-number">4.2</span> Logit Training #1 Using 20 Features</h2>
<ul>
<li>The first training run is to determine if all 20 features (amino acids) are necessary for our logistic regression model.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="kw">registerDoMC</span>(<span class="dt">cores =</span> <span class="dv">3</span>)      <span class="co"># Start multi-processor mode</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">start_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()     <span class="co"># Start timer</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="co"># Create model, 10X fold CV repeated 5X</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">tcontrol &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</a>
<a class="sourceLine" id="cb4-7" data-line-number="7">                         <span class="dt">number =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb4-8" data-line-number="8">                         <span class="dt">repeats =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb4-9" data-line-number="9"></a>
<a class="sourceLine" id="cb4-10" data-line-number="10">model_obj<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">train</span>(Class <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb4-11" data-line-number="11">                     <span class="dt">data =</span> training_set<span class="fl">.1</span>,</a>
<a class="sourceLine" id="cb4-12" data-line-number="12">                     <span class="dt">trControl =</span> tcontrol,</a>
<a class="sourceLine" id="cb4-13" data-line-number="13">                     <span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>,</a>
<a class="sourceLine" id="cb4-14" data-line-number="14">                     <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb4-15" data-line-number="15"></a>
<a class="sourceLine" id="cb4-16" data-line-number="16">end_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()      <span class="co"># End timer</span></a>
<a class="sourceLine" id="cb4-17" data-line-number="17">end_time <span class="op">-</span><span class="st"> </span>start_time       <span class="co"># Display time</span></a></code></pre></div>
<pre><code>## Time difference of 4.5237 secs</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">registerDoSEQ</span>()             <span class="co"># Stop multi-processor mode</span></a></code></pre></div>
</div>
<div id="logit-results-1" class="section level2">
<h2><span class="header-section-number">4.3</span> Logit Results #1</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">summary</span>(model_obj<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## NULL
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.9372  -0.2835  -0.0194   0.0516   3.6884  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   8.0525     9.2156   0.874 0.382234    
## A             5.0438     9.6899   0.521 0.602699    
## C           -14.2228     2.6949  -5.278 1.31e-07 ***
## D           -36.2676     8.0845  -4.486 7.25e-06 ***
## E            27.6016    11.1292   2.480 0.013135 *  
## F             5.6174     5.2654   1.067 0.286034    
## G           -22.1970    10.3043  -2.154 0.031229 *  
## H            90.1101    12.1105   7.441 1.00e-13 ***
## I            -5.9795     4.3945  -1.361 0.173610    
## K            -2.8961     9.8468  -0.294 0.768669    
## L            -3.7417     9.2217  -0.406 0.684926    
## M            -0.1427    12.0747  -0.012 0.990570    
## N             3.3478     9.6749   0.346 0.729319    
## P           -39.7466    11.1010  -3.580 0.000343 ***
## Q            -5.6804    11.2516  -0.505 0.613664    
## R           -83.6045    11.8104  -7.079 1.45e-12 ***
## S            -9.9745    10.0872  -0.989 0.322750    
## T           -36.5980     9.2791  -3.944 8.01e-05 ***
## V            16.3411     9.7859   1.670 0.094946 .  
## W             9.0169    13.8870   0.649 0.516141    
## Y           -31.9282    11.1167  -2.872 0.004078 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2593.68  on 1872  degrees of freedom
## Residual deviance:  657.72  on 1852  degrees of freedom
## AIC: 699.72
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>The Akaike information criterion (AIC)<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> for model #1 is 699.72. This will be used later to compare the models generated to rate their ability to utilize the features best.
- The list of probabilities for the estimates leaves us with only <strong>9 important features</strong> to try re-modeling, R, H, P, C, E, Y, T, D, G.</p>
</div>
<div id="logit-training-2-using-9-features" class="section level2">
<h2><span class="header-section-number">4.4</span> Logit Training #2 Using 9 Features</h2>
<ul>
<li>This test uses <strong>ONLY</strong> 9 features: (R, H, P, C, E, Y, T, D, G)</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># Data import &amp; handling</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">c_m_9aa &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;./00-data/02-aac_dpc_values/c_m_TRANSFORMED.csv&quot;</span>,</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">                    <span class="dt">col_types =</span> <span class="kw">cols</span>(<span class="dt">Class =</span> <span class="kw">col_factor</span>(<span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0&quot;</span>, <span class="st">&quot;1&quot;</span>)),</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">                                     <span class="dt">A =</span> <span class="kw">col_skip</span>(), <span class="dt">F =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">                                     <span class="dt">I =</span> <span class="kw">col_skip</span>(), <span class="dt">K =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb9-6" data-line-number="6">                                     <span class="dt">L =</span> <span class="kw">col_skip</span>(), <span class="dt">M =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb9-7" data-line-number="7">                                     <span class="dt">N =</span> <span class="kw">col_skip</span>(), <span class="dt">PID =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb9-8" data-line-number="8">                                     <span class="dt">Q =</span> <span class="kw">col_skip</span>(), <span class="dt">V =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb9-9" data-line-number="9">                                     <span class="dt">S =</span> <span class="kw">col_skip</span>(), <span class="dt">TotalAA =</span> <span class="kw">col_skip</span>(),</a>
<a class="sourceLine" id="cb9-10" data-line-number="10">                                     <span class="dt">W =</span> <span class="kw">col_skip</span>()))</a></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co"># Partition data into training and testing sets</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(c_m_9aa<span class="op">$</span>Class, <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"></a>
<a class="sourceLine" id="cb10-5" data-line-number="5">training_set<span class="fl">.2</span> &lt;-<span class="st"> </span>c_m_9aa[ index, ]</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">test_set<span class="fl">.2</span>     &lt;-<span class="st"> </span>c_m_9aa[<span class="op">-</span>index, ]</a>
<a class="sourceLine" id="cb10-7" data-line-number="7"></a>
<a class="sourceLine" id="cb10-8" data-line-number="8">Class_test<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test_set<span class="fl">.2</span><span class="op">$</span>Class)</a></code></pre></div>
<div id="logit-training-2-using-9-features-1" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Logit Training #2 Using 9 Features</h3>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="kw">registerDoMC</span>(<span class="dt">cores =</span> <span class="dv">3</span>)           <span class="co"># Start multi-core</span></a>
<a class="sourceLine" id="cb11-3" data-line-number="3">start_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()          <span class="co"># Start timer</span></a>
<a class="sourceLine" id="cb11-4" data-line-number="4"></a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="co"># Create model, 10X fold CV repeated 5X</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6">fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</a>
<a class="sourceLine" id="cb11-7" data-line-number="7">                           <span class="dt">number =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb11-8" data-line-number="8">                           <span class="dt">repeats =</span> <span class="dv">5</span>,</a>
<a class="sourceLine" id="cb11-9" data-line-number="9">                           <span class="dt">savePredictions =</span> <span class="st">&quot;final&quot;</span>) <span class="co"># IMPORTANT: Saves predictions</span></a>
<a class="sourceLine" id="cb11-10" data-line-number="10"></a>
<a class="sourceLine" id="cb11-11" data-line-number="11">model_obj<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">train</span>(Class <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb11-12" data-line-number="12">                     <span class="dt">data =</span> training_set<span class="fl">.2</span>,</a>
<a class="sourceLine" id="cb11-13" data-line-number="13">                     <span class="dt">trControl =</span> fitControl,</a>
<a class="sourceLine" id="cb11-14" data-line-number="14">                     <span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>,</a>
<a class="sourceLine" id="cb11-15" data-line-number="15">                     <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb11-16" data-line-number="16"></a>
<a class="sourceLine" id="cb11-17" data-line-number="17">end_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()           <span class="co"># End timer</span></a>
<a class="sourceLine" id="cb11-18" data-line-number="18">end_time <span class="op">-</span><span class="st"> </span>start_time            <span class="co"># Display time</span></a></code></pre></div>
<pre><code>## Time difference of 3.587111 secs</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">registerDoSEQ</span>()                  <span class="co"># Stop multi-core</span></a></code></pre></div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="logit-summary-2" class="section level2">
<h2><span class="header-section-number">4.5</span> Logit Summary #2</h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">summary</span>(model_obj<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>## 
## Call:
## NULL
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.2083  -0.2984  -0.0204   0.0601   3.5666  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    8.306      1.007   8.245  &lt; 2e-16 ***
## C            -14.755      1.908  -7.733 1.05e-14 ***
## D            -31.411      4.949  -6.347 2.20e-10 ***
## E             21.932      5.092   4.307 1.66e-05 ***
## G            -23.259      5.071  -4.587 4.49e-06 ***
## H             94.580      8.431  11.218  &lt; 2e-16 ***
## P            -29.394      6.264  -4.692 2.70e-06 ***
## R            -82.809      6.363 -13.015  &lt; 2e-16 ***
## T            -40.915      5.624  -7.275 3.45e-13 ***
## Y            -37.860      6.291  -6.018 1.77e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2593.68  on 1872  degrees of freedom
## Residual deviance:  688.96  on 1863  degrees of freedom
## AIC: 708.96
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<div style="page-break-after: always;"></div>
</div>
<div id="logit-confusion-matrix-2" class="section level2">
<h2><span class="header-section-number">4.6</span> Logit Confusion Matrix #2</h2>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">Predicted_test_vals &lt;-<span class="st"> </span><span class="kw">predict</span>(model_obj<span class="fl">.2</span>, test_set<span class="fl">.2</span>[, <span class="dv">-1</span>])</a>
<a class="sourceLine" id="cb16-2" data-line-number="2"></a>
<a class="sourceLine" id="cb16-3" data-line-number="3"><span class="kw">confusionMatrix</span>(Predicted_test_vals, Class_test<span class="fl">.2</span>, <span class="dt">positive =</span> <span class="st">&quot;1&quot;</span>)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 235  18
##          1   8 206
##                                           
##                Accuracy : 0.9443          
##                  95% CI : (0.9195, 0.9633)
##     No Information Rate : 0.5203          
##     P-Value [Acc &gt; NIR] : &lt; 2e-16         
##                                           
##                   Kappa : 0.8883          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.07756         
##                                           
##             Sensitivity : 0.9196          
##             Specificity : 0.9671          
##          Pos Pred Value : 0.9626          
##          Neg Pred Value : 0.9289          
##              Prevalence : 0.4797          
##          Detection Rate : 0.4411          
##    Detection Prevalence : 0.4582          
##       Balanced Accuracy : 0.9434          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<ul>
<li>The Akaike information criterion (AIC) for model #2 is 708.96. This will be used later to compare the models generated to rate their ability to utilize the features best.</li>
<li>The number of unique false-positives and false-negatives is 26.</li>
</ul>
</div>
<div id="obtain-list-of-false-positives-false-negatives" class="section level2">
<h2><span class="header-section-number">4.7</span> Obtain List of False Positives &amp; False Negatives</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">fp_fn_logit &lt;-<span class="st"> </span>model_obj<span class="fl">.2</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pluck</span>(<span class="st">&quot;pred&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">filter</span>(obs <span class="op">!=</span><span class="st"> </span>pred)</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="co"># Write CSV in R</span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="kw">write.table</span>(fp_fn_logit,</a>
<a class="sourceLine" id="cb18-5" data-line-number="5">            <span class="dt">file =</span> <span class="st">&quot;./00-data/03-ml_results/fp_fn_logit.csv&quot;</span>,</a>
<a class="sourceLine" id="cb18-6" data-line-number="6">            <span class="dt">row.names =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb18-7" data-line-number="7">            <span class="dt">na =</span> <span class="st">&quot;&quot;</span>,</a>
<a class="sourceLine" id="cb18-8" data-line-number="8">            <span class="dt">col.names =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb18-9" data-line-number="9">            <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)</a>
<a class="sourceLine" id="cb18-10" data-line-number="10"></a>
<a class="sourceLine" id="cb18-11" data-line-number="11"><span class="kw">nrow</span>(fp_fn_logit) <span class="co">## </span><span class="al">NOTE</span><span class="co">: NOT UNIQUE NOR SORTED</span></a></code></pre></div>
<pre><code>## [1] 536</code></pre>
<ul>
<li>The logistic regression second test produced 536 protein samples, which are either false-positives or false-negatives. The list of 536 proteins may have duplicates. Therefore they are NOT UNIQUE NOR SORTED.</li>
</ul>
</div>
<div id="logit-results" class="section level2">
<h2><span class="header-section-number">4.8</span> Logit Results</h2>
<p>Logit is easy to implement and understand and can be used for feature selection.</p>
<p>Considering the table Logit Models, below, it is clear that model #2 with nine features best describes the better of the two models.</p>
<p>Akaike Information Criterion <a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p><span class="math display">\[\begin{equation}
AIC ~=~ 2 K ~-~ ln (\widehat{L})
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(ln (\widehat{L})\)</span> is the log-likelihood, <span class="math inline">\(K\)</span> is the number of parameters.</p>
<div id="two-logit-models" class="section level4 unnumbered">
<h4>Two Logit Models</h4>
<table>
<thead>
<tr class="header">
<th align="center">Model #</th>
<th align="center">Features</th>
<th align="center">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">20</td>
<td align="center">699.72</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">9</td>
<td align="center">708.96</td>
</tr>
</tbody>
</table>
<p>Logit is a common machine learning method. It is easy to understand and explain. This supervised binary classification method is very useful for determining the importance of the features which can be applied. As we saw in Model#1, there were 11 features that had probabilities of the estimates used above the 5% threshold cut-off. In Model#2, only nine features were used to describe the model, and the AIC increased by 9.24.</p>
<p>The nine features which best described the logistic regression model were R, H, P, C, E, Y, T, D, G. If we compare this to the Boruta test carried out in the EDA, we find the overlap interesting.</p>
</div>
<div id="comparison-of-boruta-vs-logit-order-of-importance" class="section level4 unnumbered">
<h4>Comparison of Boruta Vs Logit: Order of Importance</h4>
<table>
<thead>
<tr class="header">
<th align="center">Model</th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
<th align="left">5</th>
<th align="left">6</th>
<th align="left">7</th>
<th align="left">8</th>
<th align="left">9</th>
<th align="left">10</th>
<th align="left">11</th>
<th align="left">12</th>
<th align="left">13</th>
<th align="left">14</th>
<th align="left">15</th>
<th align="left">16</th>
<th align="left">17</th>
<th align="left">18</th>
<th align="left">19</th>
<th align="left">20</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Boruta</td>
<td align="left">R</td>
<td align="left">H</td>
<td align="left">P</td>
<td align="left">K</td>
<td align="left">C</td>
<td align="left">E</td>
<td align="left">Y</td>
<td align="left">T</td>
<td align="left">S</td>
<td align="left">A</td>
<td align="left">V</td>
<td align="left">U</td>
<td align="left">I</td>
<td align="left">F</td>
<td align="left">D</td>
<td align="left">G</td>
<td align="left">N</td>
<td align="left">L</td>
<td align="left">M</td>
<td align="left">Q</td>
</tr>
<tr class="even">
<td align="center">Logit-9</td>
<td align="left">R</td>
<td align="left">H</td>
<td align="left">P</td>
<td align="left">.</td>
<td align="left">C</td>
<td align="left">E</td>
<td align="left">Y</td>
<td align="left">T</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">D</td>
<td align="left">G</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
</tbody>
</table>
<p>The first 7 out of 8 amino acid features are seen in the proper order, as described by the Boruta Random Forest model. This is confirmation that Logit can pick up the importance of features similar to Boruta.</p>
<p>Logit produced 536 proteins, which are false-negatives or false-positives. It should be noted that the 536 are NOT UNIQUE NOR SORTED. The number of unique FN/FP from the confusion matrix is 26. These proteins will be investigated further in the Outliers chapter, which compares these FN/FP proteins to the PCA outliers.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/Malthusian_growth_model" class="uri">https://en.wikipedia.org/wiki/Malthusian_growth_model</a><a href="logistic-regression-for-binary-classification.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="https://en.wikipedia.org/wiki/Logistic_function" class="uri">https://en.wikipedia.org/wiki/Logistic_function</a><a href="logistic-regression-for-binary-classification.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><a href="http://juangabrielgomila.com/en/logistic-regression-derivation/" class="uri">http://juangabrielgomila.com/en/logistic-regression-derivation/</a><a href="logistic-regression-for-binary-classification.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p><a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" class="uri">https://en.wikipedia.org/wiki/Akaike_information_criterion</a><a href="logistic-regression-for-binary-classification.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" class="uri">https://en.wikipedia.org/wiki/Akaike_information_criterion</a><a href="logistic-regression-for-binary-classification.html#fnref5" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="principle-component-analysis-of-a-binary-classification-system.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="neural-networks.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
