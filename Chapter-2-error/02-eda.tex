\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Exploratory Data Analysis},
            pdfauthor={mcc},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\title{Exploratory Data Analysis}
\author{mcc}
\date{3/13/2020}

\begin{document}
\maketitle

\hypertarget{exploratory-data-analysis}{%
\section{Exploratory Data Analysis}\label{exploratory-data-analysis}}

\begin{quote}
``Exploratory data analysis (EDA) is an approach to analyzing data sets
to summarize their main characteristics, often with visual methods.''
\footnote{\url{https://en.wikipedia.org/wiki/Exploratory_data_analysis}}
\end{quote}

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

The experiment described herein involves taking groups of proteins from
the Uniprot.org database and comparing how well different machine
learning techniques do at separating the positive from the negative
control grouping. In this circumstance, proteins from the myoglobin
family are analyzed against randomly chosen human proteins, which are
not related to hemoglobin or myoglobin.

This work is to characterize the \emph{anomalous points} derived from
PCA and compare them to the false-positives and false-negatives
generated from each of six machine learning approaches produces. For the
sake of this paper \emph{anomalous points} are defined as values greater
than the absolute value of three times the standard deviation from of
the first and second principal components.

\begin{equation}
Anomalous ~Points > | 3 \sigma | ~~~where~~~ \sigma = \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2}
\end{equation}

Therefore the M.L techniques will be:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Principal Component Analysis,
\item
  Logistic Regression,
\item
  SVM-Linear,
\item
  SVM-polynomial,
\item
  SVM-RBF,
\item
  Neural Network.
\end{enumerate}

\hypertarget{four-step-analysis}{%
\subsubsection{Four-Step Analysis}\label{four-step-analysis}}

At this stage, data is inspected in a careful and structured way. Hence,
I have chosen a four-step process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Hypothesize,
\item
  Summarize,
\item
  Visualize,
\item
  Normalize.
\end{enumerate}

\hypertarget{useful-guides-for-exploratory-data-analysis}{%
\subsubsection{Useful Guides for Exploratory Data
Analysis}\label{useful-guides-for-exploratory-data-analysis}}

The summarization of the amino acid dataset is based on a hybrid set of
guidelines;

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  NIST Handbook of Statistics,\footnote{\url{https://www.itl.nist.gov/div898/handbook/}}
\item
  Exploratory Data Analysis With R by Roger Peng,\footnote{Roger Peng,
    Exploratory Data Analysis with R, \url{https://leanpub.com/exdata},
    2016}
\item
  Exploratory Data Analysis Using R by Ronald K. Pearson.\footnote{Ronald
    Pearson, Exploratory Data Analysis Using R, CRC Press,
    \url{ISBN:9781138480605}, 2018}
\end{enumerate}

\hypertarget{questions-during-eda}{%
\subsubsection{Questions During EDA}\label{questions-during-eda}}

Although exploratory data analysis does not always have a formal
hypothesis testing portion, I do, however, pose several questions
concerning the structure, quality, and types of data.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Do the independent variables of this study have large skewed
  distributions?

  1.1 If skews are greater than 2.0, then can a transformation be used
  for normalization?

  1.2 Determine what transformation to use?
\item
  Can Feature Selection be used, and which procedures are appropriate?

  2.1 Use the Random Forest technique known as Boruta\footnote{Miron
    Kursa, Witold Rudnicki, Feature Selection with the Boruta Package,
    \url{DOI:10.18637/jss.v036.i11}, 2010} for feature importance or
  reduction?

  2.2 Will coefficients of correlation (R) find collinearity and reduce
  the number of features?

  2.3 Will principal component analysis (PCA) be useful in finding
  hidden structures of patterns?

  2.4 Can PCA be used successfully for Feature Selection?
\item
  What is the structure of the data?

  3.1 Is the data representative of the entire experimental space?

  3.2 Is missing data an issue?

  3.3 Does the data have certain biases, either known or unknown?

  3.4 What relationships do we expect from these variables?\footnote{Ronald
    Pearson, Exploratory Data Analysis Using R, CRC Press,
    \url{ISBN:9781138480605}, 2018}
\end{enumerate}

\hypertarget{analysis-of-raw-data}{%
\subsection{Analysis of RAW data}\label{analysis-of-raw-data}}

Raw data is considered:
\texttt{./00-data/02-aac\_dpc\_values/c\_m\_RAW\_AAC.csv}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Import libraries}
\NormalTok{Libraries <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"knitr"}\NormalTok{, }\StringTok{"readr"}\NormalTok{, }\StringTok{"RColorBrewer"}\NormalTok{, }\StringTok{"corrplot"}\NormalTok{, }\StringTok{"doMC"}\NormalTok{, }\StringTok{"Boruta"}\NormalTok{, }\StringTok{"kableExtra"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in}\NormalTok{ Libraries) \{}
\KeywordTok{library}\NormalTok{(i, }\DataTypeTok{character.only =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Import RAW data}
\NormalTok{c_m_RAW_AAC <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"./00-data/02-aac_dpc_values/c_m_RAW_AAC.csv"}\NormalTok{)}
\NormalTok{Class <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(c_m_RAW_AAC}\OperatorTok{$}\NormalTok{Class)}
\end{Highlighting}
\end{Shaded}

\hypertarget{visually-inspect-raw-data-files}{%
\subsubsection{Visually inspect RAW data
files}\label{visually-inspect-raw-data-files}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use the command-line interface followed by the command \texttt{less.}
\item
  Check for binary instead of ASCII and bad Unicode.
\end{enumerate}

\hypertarget{inspect-raw-dataframe-structure-str}{%
\subsubsection{\texorpdfstring{Inspect RAW dataframe structure,
\texttt{str()}}{Inspect RAW dataframe structure, str()}}\label{inspect-raw-dataframe-structure-str}}

\begin{verbatim}
## Classes 'spec_tbl_df', 'tbl_df', 'tbl' and 'data.frame': 2340 obs. of  23 variables:
##  $ Class  : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TotalAA: num  226 221 624 1014 699 ...
##  $ PID    : chr  "C1" "C2" "C3" "C4" ...
##  $ A      : num  0.2655 0.2081 0.0433 0.0661 0.0644 ...
##  $ C      : num  0 0 0.00962 0.01381 0.03577 ...
##  $ D      : num  0.00442 0.00452 0.04647 0.06114 0.02861 ...
##  $ E      : num  0.031 0.0271 0.0833 0.074 0.0472 ...
##  $ F      : num  0.00442 0.00452 0.02564 0.02959 0.06295 ...
##  $ G      : num  0.0708 0.0769 0.0817 0.07 0.0443 ...
##  $ H      : num  0 0 0.0176 0.0187 0.0157 ...
##  $ I      : num  0.00885 0.0181 0.03045 0.04734 0.0701 ...
##  $ K      : num  0.28761 0.27602 0.00962 0.12426 0.05579 ...
##  $ L      : num  0.0442 0.0452 0.0577 0.0888 0.1359 ...
##  $ M      : num  0.00442 0.00452 0.01442 0.02465 0.02289 ...
##  $ N      : num  0.0177 0.0136 0.0641 0.0355 0.0558 ...
##  $ P      : num  0.0841 0.0995 0.0449 0.0434 0.0472 ...
##  $ Q      : num  0.00442 0.00905 0.04327 0.03353 0.02861 ...
##  $ R      : num  0.0133 0.0181 0.1202 0.0325 0.0415 ...
##  $ S      : num  0.0575 0.0724 0.1875 0.0838 0.0787 ...
##  $ T      : num  0.0531 0.0633 0.0625 0.0414 0.0744 ...
##  $ V      : num  0.0442 0.0543 0.0385 0.0671 0.0458 ...
##  $ W      : num  0 0 0.00481 0.01282 0.00715 ...
##  $ Y      : num  0.00442 0.00452 0.01442 0.03156 0.0372 ...
##  - attr(*, "spec")=
##   .. cols(
##   ..   Class = col_double(),
##   ..   TotalAA = col_double(),
##   ..   PID = col_character(),
##   ..   A = col_double(),
##   ..   C = col_double(),
##   ..   D = col_double(),
##   ..   E = col_double(),
##   ..   F = col_double(),
##   ..   G = col_double(),
##   ..   H = col_double(),
##   ..   I = col_double(),
##   ..   K = col_double(),
##   ..   L = col_double(),
##   ..   M = col_double(),
##   ..   N = col_double(),
##   ..   P = col_double(),
##   ..   Q = col_double(),
##   ..   R = col_double(),
##   ..   S = col_double(),
##   ..   T = col_double(),
##   ..   V = col_double(),
##   ..   W = col_double(),
##   ..   Y = col_double()
##   .. )
\end{verbatim}

\newpage

\hypertarget{check-raw-data-head-tail}{%
\subsubsection{\texorpdfstring{Check RAW data \texttt{head} \&
\texttt{tail}}{Check RAW data head \& tail}}\label{check-raw-data-head-tail}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(c_m_RAW_AAC, }\DataTypeTok{n =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 23
##   Class TotalAA PID       A     C       D      E       F      G     H       I
##   <dbl>   <dbl> <chr> <dbl> <dbl>   <dbl>  <dbl>   <dbl>  <dbl> <dbl>   <dbl>
## 1     0     226 C1    0.265     0 0.00442 0.0310 0.00442 0.0708     0 0.00885
## 2     0     221 C2    0.208     0 0.00452 0.0271 0.00452 0.0769     0 0.0181 
## # ... with 12 more variables: K <dbl>, L <dbl>, M <dbl>, N <dbl>, P <dbl>,
## #   Q <dbl>, R <dbl>, S <dbl>, T <dbl>, V <dbl>, W <dbl>, Y <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tail}\NormalTok{(c_m_RAW_AAC, }\DataTypeTok{n =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 23
##   Class TotalAA PID        A       C      D      E      F      G      H      I
##   <dbl>   <dbl> <chr>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>
## 1     1     335 M1123 0.0567 0.00299 0.0537 0.0716 0.0507 0.0507 0.0388 0.0776
## 2     1      43 M1124 0.0698 0       0.116  0.116  0.0930 0.0465 0      0.0233
## # ... with 12 more variables: K <dbl>, L <dbl>, M <dbl>, N <dbl>, P <dbl>,
## #   Q <dbl>, R <dbl>, S <dbl>, T <dbl>, V <dbl>, W <dbl>, Y <dbl>
\end{verbatim}

\hypertarget{check-raw-data-types}{%
\subsubsection{Check RAW data types}\label{check-raw-data-types}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{is.data.frame}\NormalTok{(c_m_RAW_AAC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(c_m_RAW_AAC}\OperatorTok{$}\NormalTok{Class) }\CommentTok{# Col 1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(c_m_RAW_AAC}\OperatorTok{$}\NormalTok{TotalAA) }\CommentTok{# Col 2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(c_m_RAW_AAC}\OperatorTok{$}\NormalTok{PID) }\CommentTok{# Col 3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(c_m_RAW_AAC}\OperatorTok{$}\NormalTok{A) }\CommentTok{# Col 4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\hypertarget{check-raw-dataframe-dimensions}{%
\subsubsection{Check RAW dataframe
dimensions}\label{check-raw-dataframe-dimensions}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(c_m_RAW_AAC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2340   23
\end{verbatim}

\hypertarget{check-raw-for-missing-values}{%
\subsubsection{Check RAW for missing
values}\label{check-raw-for-missing-values}}

\begin{itemize}
\tightlist
\item
  \textbf{No missing values found.}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{apply}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(c_m_RAW_AAC), }\DecValTok{2}\NormalTok{, which)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## integer(0)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# sapply(c_m_RAW_AAC, function(x) sum(is.na(x))) # Sum up NA by columns}
\CommentTok{# c_m_RAW_AAC[rowSums(is.na(c_m_RAW_AAC)) != 0,] # Show rows where NA's is not zero}
\end{Highlighting}
\end{Shaded}

\hypertarget{number-of-polypeptides-per-class}{%
\subsubsection{Number of polypeptides per
Class:}\label{number-of-polypeptides-per-class}}

\begin{itemize}
\tightlist
\item
  Class 0 = Control,
\item
  Class 1 = Myoglobin
\end{itemize}

\begin{verbatim}
## 
##    0    1 
## 1216 1124
\end{verbatim}

\hypertarget{numerical-summary-of-raw-data}{%
\subsubsection{Numerical summary of RAW
data}\label{numerical-summary-of-raw-data}}

\begin{verbatim}
##      Class           TotalAA           PID                  A          
##  Min.   :0.0000   Min.   :   2.0   Length:2340        Min.   :0.00000  
##  1st Qu.:0.0000   1st Qu.: 109.8   Class :character   1st Qu.:0.05108  
##  Median :0.0000   Median : 154.0   Mode  :character   Median :0.07364  
##  Mean   :0.4803   Mean   : 353.8                      Mean   :0.07835  
##  3rd Qu.:1.0000   3rd Qu.: 407.0                      3rd Qu.:0.10261  
##  Max.   :1.0000   Max.   :4660.0                      Max.   :0.28000  
##        C                  D                 E                 F          
##  Min.   :0.000000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.000000   1st Qu.:0.03401   1st Qu.:0.05435   1st Qu.:0.03801  
##  Median :0.007034   Median :0.05195   Median :0.07143   Median :0.04545  
##  Mean   :0.011970   Mean   :0.04900   Mean   :0.07451   Mean   :0.05135  
##  3rd Qu.:0.020408   3rd Qu.:0.06567   3rd Qu.:0.09091   3rd Qu.:0.05501  
##  Max.   :0.159420   Max.   :0.17647   Max.   :0.50000   Max.   :0.37500  
##        G                 H                 I                 K          
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.04544   1st Qu.:0.01324   1st Qu.:0.04348   1st Qu.:0.05797  
##  Median :0.06394   Median :0.02297   Median :0.05992   Median :0.08182  
##  Mean   :0.06193   Mean   :0.02890   Mean   :0.06839   Mean   :0.08386  
##  3rd Qu.:0.08625   3rd Qu.:0.04095   3rd Qu.:0.08216   3rd Qu.:0.12081  
##  Max.   :0.36364   Max.   :0.13333   Max.   :0.50000   Max.   :0.28761  
##        L                 M                 N                 P          
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.07480   1st Qu.:0.01087   1st Qu.:0.01948   1st Qu.:0.02464  
##  Median :0.09136   Median :0.01948   Median :0.04145   Median :0.03401  
##  Mean   :0.09313   Mean   :0.01949   Mean   :0.04228   Mean   :0.03825  
##  3rd Qu.:0.11688   3rd Qu.:0.02721   3rd Qu.:0.05788   3rd Qu.:0.04772  
##  Max.   :0.25000   Max.   :0.11111   Max.   :0.12563   Max.   :0.20635  
##        Q                 R                 S                 T          
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.02212   1st Qu.:0.01476   1st Qu.:0.04348   1st Qu.:0.03247  
##  Median :0.03598   Median :0.03896   Median :0.05564   Median :0.05194  
##  Mean   :0.03342   Mean   :0.03818   Mean   :0.06191   Mean   :0.04838  
##  3rd Qu.:0.04545   3rd Qu.:0.05370   3rd Qu.:0.06964   3rd Qu.:0.06522  
##  Max.   :0.18182   Max.   :0.24324   Max.   :0.22619   Max.   :0.18750  
##        V                 W                  Y          
##  Min.   :0.00000   Min.   :0.000000   Min.   :0.00000  
##  1st Qu.:0.04575   1st Qu.:0.001899   1st Qu.:0.01463  
##  Median :0.05844   Median :0.011492   Median :0.02865  
##  Mean   :0.06512   Mean   :0.012327   Mean   :0.03644  
##  3rd Qu.:0.07405   3rd Qu.:0.017889   3rd Qu.:0.04564  
##  Max.   :0.20000   Max.   :0.133333   Max.   :0.14286
\end{verbatim}

\hypertarget{visualize-descriptive-statistics-using-raw-data}{%
\subsubsection{Visualize Descriptive Statistics using RAW
Data}\label{visualize-descriptive-statistics-using-raw-data}}

Formulas for mean: \begin{equation} 
E[X] = \sum_{i=1}^n x_i p_i ~~; ~~~~~~ \bar x = \frac {1}{n} \sum_{i=1}^n x_i
\end{equation}

\hypertarget{scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-of-raw-data}{%
\subsubsection{\texorpdfstring{Scatter plot of means of
\emph{Myoglobin-Control} amino acid composition of RAW
Data}{Scatter plot of means of Myoglobin-Control amino acid composition of RAW Data}}\label{scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-of-raw-data}}

\begin{itemize}
\tightlist
\item
  This Scatter-plot shows the means for each feature (column-means) in
  the dataset. The means represent the ungrouped or total of all
  proteins (where n = 2340) versus AA type.
\end{itemize}

\begin{center}\includegraphics[width=0.6\linewidth]{02-eda_files/figure-latex/212-1} \end{center}

\hypertarget{means-of-percent-amino-acid-composition-of-control-myoglobin-categories-raw-data}{%
\subsubsection{Means of percent amino acid composition of control \&
myoglobin categories, RAW
data}\label{means-of-percent-amino-acid-composition-of-control-myoglobin-categories-raw-data}}

\includegraphics{02-eda_files/figure-latex/215-1.pdf}

\hypertarget{boxplots-of-grand-means-of-overall-amino-acid-composition-raw-data}{%
\subsubsection{Boxplots of grand-means of overall amino acid
composition, RAW
data}\label{boxplots-of-grand-means-of-overall-amino-acid-composition-raw-data}}

\includegraphics{02-eda_files/figure-latex/216-1.pdf}

\hypertarget{boxplots-of-amino-acid-compositions-for-control-only-raw-data}{%
\subsubsection{Boxplots of amino acid compositions for control (only),
RAW
data}\label{boxplots-of-amino-acid-compositions-for-control-only-raw-data}}

\includegraphics{02-eda_files/figure-latex/217-1.pdf}

\hypertarget{boxplots-of-amino-acid-compositions-for-myoglobin-only-raw-data}{%
\subsubsection{Boxplots of amino acid compositions for myoglobin (only),
RAW
data}\label{boxplots-of-amino-acid-compositions-for-myoglobin-only-raw-data}}

\includegraphics{02-eda_files/figure-latex/218-1.pdf}

\includegraphics{02-eda_files/figure-latex/219-1.pdf}

\hypertarget{boxplots-of-length-of-polypeptides-for-raw-data}{%
\subsubsection{Boxplots Of Length Of Polypeptides For RAW
Data}\label{boxplots-of-length-of-polypeptides-for-raw-data}}

\includegraphics{02-eda_files/figure-latex/220-1.pdf}

\hypertarget{plot-coefficient-of-variance-for-raw-data}{%
\subsubsection{Plot Coefficient Of Variance For RAW
Data}\label{plot-coefficient-of-variance-for-raw-data}}

Standard deviations are sensitive to scale. Therefore I compare the
normalized standard deviations. This normalized standard deviation is
more commonly called the coefficient of variation (CV).

\begin{equation} 
CV = \frac {\sigma (x)} {E [|x|]} ~~~ where ~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}

\begin{equation} 
CV ~~=~~ \frac{1}{\bar x} \cdot \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2}
\end{equation}

\includegraphics{02-eda_files/figure-latex/221-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AA_var_norm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         A         C         D         E         F         G         H         I 
## 0.6095112 1.2444944 0.5478540 0.4156102 0.5436243 0.5201625 0.7966296 0.6005962 
##         K         L         M         N         P         Q         R         S 
## 0.4689544 0.3215591 0.6529752 0.7352478 0.7383244 0.5752622 0.7680977 0.4948690 
##         T         V         W         Y 
## 0.5830352 0.4420595 0.9461276 0.8461615
\end{verbatim}

\newpage

\hypertarget{skewness-of-distributions-raw-data}{%
\subsubsection{Skewness of distributions, RAW
data}\label{skewness-of-distributions-raw-data}}

\begin{equation} 
Skewness ~= E\left[ \left( \frac{X - \mu}{\sigma(x)} \right)^3 \right] ~~~~ where ~~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}

\begin{equation} 
Skewness ~= \frac { \frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^3 } { \left( \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2 } \right) ^ {3}}
\end{equation}

Skewness values for each A.A. are determined in totality.

\includegraphics{02-eda_files/figure-latex/223-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AA_skewness}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            A            C            D            E            F            G 
##  0.670502595  2.538162400 -0.058540442  1.782876260  2.128117638  0.091338300 
##            H            I            K            L            M            N 
##  1.135783661  2.192145038  0.223433207 -0.172566877  0.744002991  0.633532783 
##            P            Q            R            S            T            V 
##  1.493903282  0.306716333  1.241930812  1.448521897 -0.006075043  1.338971930 
##            W            Y 
##  1.831047440  1.694362388
\end{verbatim}

\hypertarget{qq-plots-of-20-amino-acids-raw-data}{%
\subsubsection{QQ-Plots of 20 amino acids, RAW
data}\label{qq-plots-of-20-amino-acids-raw-data}}

\includegraphics{02-eda_files/figure-latex/224-1.pdf}
\includegraphics{02-eda_files/figure-latex/224-2.pdf}
\includegraphics{02-eda_files/figure-latex/224-3.pdf}
\includegraphics{02-eda_files/figure-latex/224-4.pdf}
\includegraphics{02-eda_files/figure-latex/224-5.pdf}

\hypertarget{determine-coefficients-of-correlation-raw-data}{%
\subsubsection{Determine coefficients of correlation, RAW
data}\label{determine-coefficients-of-correlation-raw-data}}

An easily interpretable test is a correlation 2D-plot for investigating
multicollinearity or feature reduction. Fewer attributes ``means
decreased computational time and complexity. Secondly, if two predictors
are highly correlated, this implies that they measure the same
underlying information. Removing one should not compromise the
performance of the model and might lead to a more parsimonious and
interpretable model. Third, some models can be crippled by predictors
with degenerate distributions.'' \footnote{Max Kuhn and Kjell Johnson,
  Applied Predictive Modeling, Springer Publishing, 2018, P.43}

Pearson's correlation coefficient: \begin{equation} 
\rho_{x,y} = \frac {E \left[(X - \mu_x)(X - \mu_y) \right]} {\sigma_x \sigma_y}
\end{equation}

\begin{equation} 
r_{xy} = \frac {\sum^n_{i=1} (x_i - \bar x)(y_1 - \bar y)} { {\sqrt {\sum^n_{i=1} (x_i - \bar x)^2 }} {\sqrt {\sum^n_{i=1} (y_i - \bar y)^2 }} }
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c_m_corr_mat <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(c_m_RAW_AAC[, }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\OperatorTok{:}\DecValTok{23}\NormalTok{)], }\DataTypeTok{method =} \StringTok{"p"}\NormalTok{) }\CommentTok{# "p": Pearson test for continous variables}

\KeywordTok{corrplot}\NormalTok{(}\KeywordTok{abs}\NormalTok{(c_m_corr_mat),}
         \DataTypeTok{title =} \StringTok{"Correlation Plot Of AAC, RAW Data"}\NormalTok{,}
         \DataTypeTok{method =} \StringTok{"square"}\NormalTok{,}
         \DataTypeTok{type =} \StringTok{"lower"}\NormalTok{,}
         \DataTypeTok{tl.pos =} \StringTok{"d"}\NormalTok{,}
         \DataTypeTok{cl.lim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{),}
         \DataTypeTok{addgrid.col =} \StringTok{"lightgrey"}\NormalTok{,}
         \DataTypeTok{cl.pos =} \StringTok{"b"}\NormalTok{,                   }\CommentTok{# Color legend position bottom.}
         \DataTypeTok{order =} \StringTok{"FPC"}\NormalTok{,                  }\CommentTok{# "FPC" = first principal component order.}
         \DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{),}
         \DataTypeTok{tl.col =} \StringTok{"black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-eda_files/figure-latex/225-1.pdf}

NOTE: Amino acids shown in First Principal Component order, top to
bottom.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Maximum value of Correlation between T \& N.
\end{enumerate}

\begin{verbatim}
## [1] 0.7098085
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  According to Max Kuhn\footnote{Max Kuhn and Kjell Johnson, Applied
    Predictive Modeling, Springer Publishing, 2018, P.47
    (\url{http://appliedpredictivemodeling.com/})}, correlation
  coefficients need only be addressed if the \textbar{}R\textbar{}
  \textgreater{}= 0.75.
\item
  Therefore is \textbf{no reason to consider multicollinearity}.
\end{enumerate}

\hypertarget{boruta-random-forest-test-raw-data}{%
\subsubsection{Boruta Random Forest Test, RAW
data}\label{boruta-random-forest-test-raw-data}}

\begin{quote}
It finds relevant features by comparing original attributes' importance
with importance achievable at random, estimated using their permuted
copies (shadows).

Miron Kursa \footnote{\url{https://notabug.org/mbq/Boruta/}}
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c_m_class_}\DecValTok{20}\NormalTok{ <-}\StringTok{ }\NormalTok{c_m_RAW_AAC[, }\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)] }\CommentTok{# Remove TotalAA & PID}
\NormalTok{Class <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(c_m_class_}\DecValTok{20}\OperatorTok{$}\NormalTok{Class) }\CommentTok{# Convert 'Class' To Factor}
\end{Highlighting}
\end{Shaded}

NOTE: \emph{mcAdj = TRUE}, If True, multiple comparisons will be
adjusted using the Bonferroni method to calculate p-values. Therefore,
\(p_i \leq \large \frac {\alpha} {m}\) where \(\alpha\) is the desired
p-value and \(m\) is the total number of null hypotheses.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1000}\NormalTok{)}
\KeywordTok{registerDoMC}\NormalTok{(}\DataTypeTok{cores =} \DecValTok{3}\NormalTok{) }\CommentTok{# Start multi-processor mode}
\NormalTok{start_time <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{() }\CommentTok{# Start timer}

\NormalTok{boruta_output <-}\StringTok{ }\KeywordTok{Boruta}\NormalTok{(Class }\OperatorTok{~}\StringTok{ }\NormalTok{.,}
                        \DataTypeTok{data =}\NormalTok{ c_m_class_}\DecValTok{20}\NormalTok{[, }\DecValTok{-1}\NormalTok{],}
                        \DataTypeTok{mcAdj =} \OtherTok{TRUE}\NormalTok{, }\CommentTok{# See Note above.}
                        \DataTypeTok{doTrace =} \DecValTok{1}\NormalTok{) }\CommentTok{# doTrace = 1, represents non-verbose mode.}

\KeywordTok{registerDoSEQ}\NormalTok{() }\CommentTok{# Stop multi-processor mode}
\NormalTok{end_time <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{() }\CommentTok{# End timer}
\NormalTok{end_time }\OperatorTok{-}\StringTok{ }\NormalTok{start_time }\CommentTok{# Display elapsed time}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 31.62754 secs
\end{verbatim}

\hypertarget{plot-variable-importance-raw-data}{%
\subsubsection{Plot variable importance, RAW
Data}\label{plot-variable-importance-raw-data}}

\includegraphics{02-eda_files/figure-latex/230-1.pdf}

\hypertarget{variable-importance-scores-raw-data}{%
\subsubsection{Variable importance scores, RAW
Data}\label{variable-importance-scores-raw-data}}

\begin{verbatim}
## Warning in TentativeRoughFix(boruta_output): There are no Tentative attributes!
## Returning original object.
\end{verbatim}

\begin{table}[H]
\centering
\begin{tabular}{l|r|l}
\hline
  & meanImp & decision\\
\hline
R & 43.18824 & Confirmed\\
\hline
H & 34.29757 & Confirmed\\
\hline
P & 28.70225 & Confirmed\\
\hline
C & 27.67710 & Confirmed\\
\hline
K & 27.60808 & Confirmed\\
\hline
E & 26.18884 & Confirmed\\
\hline
Y & 22.85337 & Confirmed\\
\hline
T & 21.67689 & Confirmed\\
\hline
S & 21.43716 & Confirmed\\
\hline
A & 20.53089 & Confirmed\\
\hline
N & 20.09681 & Confirmed\\
\hline
V & 18.77054 & Confirmed\\
\hline
I & 18.76492 & Confirmed\\
\hline
F & 18.31240 & Confirmed\\
\hline
D & 17.64592 & Confirmed\\
\hline
G & 16.15461 & Confirmed\\
\hline
W & 15.74107 & Confirmed\\
\hline
L & 15.27767 & Confirmed\\
\hline
M & 14.82861 & Confirmed\\
\hline
Q & 14.13939 & Confirmed\\
\hline
\end{tabular}
\end{table}

\hypertarget{conclusion-for-boruta-random-forest-test-raw-data}{%
\subsubsection{Conclusion for Boruta random forest test, RAW
Data}\label{conclusion-for-boruta-random-forest-test-raw-data}}

\begin{itemize}
\tightlist
\item
  All features are essential. None should be dropped.
\end{itemize}

\hypertarget{conclusions-for-eda-raw-data}{%
\subsubsection{Conclusions For EDA, RAW
data}\label{conclusions-for-eda-raw-data}}

Three amino acids (C, F, I) from the single amino acid percent
composition were deemed problematic due to their skewness were greater
than 2.0. This suggests that a transformation should be carried out to
rectify this issue.

\begin{longtable}[]{@{}lc@{}}
\toprule
Protein & Skewness\tabularnewline
\midrule
\endhead
C, Cysteine & 2.538162\tabularnewline
F, Phenolalanine & 2.128118\tabularnewline
I, Isoleucine & 2.192145\tabularnewline
\bottomrule
\end{longtable}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{analysis-of-transformed-data}{%
\subsection{Analysis of TRANSFORMED
data}\label{analysis-of-transformed-data}}

\textbf{This EDA section is a reevaluation square root transformed,
\texttt{c\_m\_RAW\_ACC.csv} data set, hence called
\texttt{c\_m\_TRANSFORMED.csv.} }

The \(\sqrt x_i\) \emph{Transformed} data is derived from
\texttt{c\_m\_RAW\_ACC.csv} where the amino acids C, F, I were
transformed using a square root function. This transformation was done
to reduce the skewness of these samples and avoid modeling problems
arising from high skewness, as seen below.

\begin{longtable}[]{@{}lcc@{}}
\toprule
Amino Acid & Initial skewness & Skew After Square-Root
Transformation\tabularnewline
\midrule
\endhead
C, Cysteine & 2.538162 & 0.3478132\tabularnewline
F, Phenolalanine & 2.128118 & -0.102739\tabularnewline
I, Isoleucine & 2.192145 & 0.2934749\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Import Transformed data}
\NormalTok{c_m_TRANSFORMED <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"./00-data/02-aac_dpc_values/c_m_TRANSFORMED.csv"}\NormalTok{)}
\NormalTok{Class <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(c_m_TRANSFORMED}\OperatorTok{$}\NormalTok{Class)}
\end{Highlighting}
\end{Shaded}

\hypertarget{check-transformed-dataframe-dimensions}{%
\subsubsection{Check Transformed dataframe
dimensions}\label{check-transformed-dataframe-dimensions}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(c_m_TRANSFORMED)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2340   23
\end{verbatim}

\hypertarget{check-transformed-for-missing-values}{%
\subsubsection{Check Transformed for missing
values}\label{check-transformed-for-missing-values}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{apply}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(c_m_TRANSFORMED), }\DecValTok{2}\NormalTok{, which)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## integer(0)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  No missing values found.
\end{itemize}

\hypertarget{count-transformed-data-for-the-number-of-polypeptides-per-class}{%
\subsubsection{Count Transformed data for the number of polypeptides per
class}\label{count-transformed-data-for-the-number-of-polypeptides-per-class}}

Number of polypeptides per Class:

\begin{itemize}
\tightlist
\item
  Class 0 = Control,
\item
  Class 1 = Myoglobin
\end{itemize}

\begin{verbatim}
## 
##    0    1 
## 1216 1124
\end{verbatim}

\hypertarget{visualization-descriptive-statistics-transformed-data}{%
\subsubsection{Visualization Descriptive Statistics, TRANSFORMED
data}\label{visualization-descriptive-statistics-transformed-data}}

Formulas for mean: \begin{equation} 
E[X] = \sum_{i=1}^n x_i p_i ~~; ~~~~~~ \bar x = \frac {1}{n} \sum_{i=1}^n x_i
\end{equation}

\hypertarget{scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-sqrt-x_i-transformed-data}{%
\subsubsection{\texorpdfstring{Scatter plot of means of
\emph{Myoglobin-Control} amino acid composition \(\sqrt x_i\),
TRANSFORMED
data}{Scatter plot of means of Myoglobin-Control amino acid composition \textbackslash{}sqrt x\_i, TRANSFORMED data}}\label{scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-sqrt-x_i-transformed-data}}

\begin{itemize}
\tightlist
\item
  This plot shows the means for each feature (column-means) in the
  dataset. The means represent the ungrouped or total of all proteins
  (where n=2340) versus AA type.
\end{itemize}

\includegraphics{02-eda_files/figure-latex/237-1.pdf}

\hypertarget{grouped-bar-chart-of-means-for-percent-amino-acid-composition-of-transformed-data-control-myoglobin-categories}{%
\subsubsection{Grouped bar chart of means for percent amino acid
composition of Transformed Data; control \& myoglobin
categories}\label{grouped-bar-chart-of-means-for-percent-amino-acid-composition-of-transformed-data-control-myoglobin-categories}}

\includegraphics{02-eda_files/figure-latex/240-1.pdf}

\hypertarget{boxplots-of-grand-means-of-the-overall-amino-acid-composition-of-square-root-transformed-data}{%
\subsubsection{Boxplots of grand-means of the overall amino acid
composition of square-root transformed
data}\label{boxplots-of-grand-means-of-the-overall-amino-acid-composition-of-square-root-transformed-data}}

\includegraphics{02-eda_files/figure-latex/241-1.pdf}

\hypertarget{boxplots-of-amino-acid-compositions-for-control-only-of-square-root-transformed-data}{%
\subsubsection{Boxplots of amino acid compositions for control (only) of
square-root transformed
data}\label{boxplots-of-amino-acid-compositions-for-control-only-of-square-root-transformed-data}}

\includegraphics{02-eda_files/figure-latex/242-1.pdf}

\hypertarget{boxplots-of-amino-acid-compositions-for-myoglobin-of-square-root-transformed-dataonly-transformed-data}{%
\subsubsection{Boxplots of amino acid compositions for myoglobin of
square-root transformed Data(only), TRANSFORMED
data}\label{boxplots-of-amino-acid-compositions-for-myoglobin-of-square-root-transformed-dataonly-transformed-data}}

\includegraphics{02-eda_files/figure-latex/243-1.pdf}

\hypertarget{boxplots-of-length-of-polypeptides-of-transformed-data-myoglobin-control-combined}{%
\subsubsection{Boxplots Of Length Of Polypeptides Of Transformed Data;
Myoglobin, Control \&
Combined}\label{boxplots-of-length-of-polypeptides-of-transformed-data-myoglobin-control-combined}}

\includegraphics{02-eda_files/figure-latex/244-1.pdf}

\newpage

\hypertarget{coefficient-of-variance-cv-transformed-data}{%
\subsubsection{Coefficient of Variance (CV), TRANSFORMED
data}\label{coefficient-of-variance-cv-transformed-data}}

Standard deviations are sensitive to scale. Therefore I compare the
normalized standard deviations. This normalized standard deviation is
more commonly called the coefficient of variation (CV).

\begin{equation} 
CV = \frac {\sigma (x)} {E [|x|]} ~~~ where ~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}

\begin{equation} 
CV ~~=~~ \frac{1}{\bar x} \cdot \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2}
\end{equation}

\hypertarget{plot-of-coefficient-of-variance-cv}{%
\subsubsection{Plot of Coefficient Of Variance
(CV)}\label{plot-of-coefficient-of-variance-cv}}

\includegraphics{02-eda_files/figure-latex/245-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AA_var_norm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         A         C         D         E         F         G         H         I 
## 0.6095112 0.8729758 0.5478540 0.4156102 0.2815745 0.5201625 0.7966296 0.2999687 
##         K         L         M         N         P         Q         R         S 
## 0.4689544 0.3215591 0.6529752 0.7352478 0.7383244 0.5752622 0.7680977 0.4948690 
##         T         V         W         Y 
## 0.5830352 0.4420595 0.9461276 0.8461615
\end{verbatim}

\newpage

\hypertarget{skewness-of-distributions-transformed-data}{%
\subsubsection{Skewness of distributions, TRANSFORMED
data}\label{skewness-of-distributions-transformed-data}}

\begin{equation} 
Skewness ~= E\left[ \left( \frac{X - \mu}{\sigma(x)} \right)^3 \right] ~~~~ where ~~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}

\begin{equation} 
Skewness ~= \frac { \frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^3 } { \left( \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2 } \right) ^ {3}}
\end{equation}

\begin{itemize}
\tightlist
\item
  Skewness values for each A.A. by Class of square-root transformed data
\end{itemize}

\includegraphics{02-eda_files/figure-latex/247-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AA_skewness}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            A            C            D            E            F            G 
##  0.670502595  0.347813248 -0.058540442  1.782876260 -0.102739748  0.091338300 
##            H            I            K            L            M            N 
##  1.135783661  0.293474879  0.223433207 -0.172566877  0.744002991  0.633532783 
##            P            Q            R            S            T            V 
##  1.493903282  0.306716333  1.241930812  1.448521897 -0.006075043  1.338971930 
##            W            Y 
##  1.831047440  1.694362388
\end{verbatim}

\hypertarget{qq-plots-of-20-amino-acids-transformed-data}{%
\subsubsection{QQ Plots of 20 amino acids, TRANSFORMED
data}\label{qq-plots-of-20-amino-acids-transformed-data}}

\includegraphics{02-eda_files/figure-latex/249-1.pdf}
\includegraphics{02-eda_files/figure-latex/249-2.pdf}
\includegraphics{02-eda_files/figure-latex/249-3.pdf}
\includegraphics{02-eda_files/figure-latex/249-4.pdf}
\includegraphics{02-eda_files/figure-latex/249-5.pdf}

\hypertarget{determine-coefficients-of-correlation-transformed-data}{%
\subsubsection{Determine coefficients of correlation, TRANSFORMED
data}\label{determine-coefficients-of-correlation-transformed-data}}

An easily interpretable test is a correlation 2D-plot for investigating
multicollinearity or feature reduction. Fewer attributes ``means
decreased computational time and complexity. Secondly, if two predictors
are highly correlated, this implies that they measure the same
underlying information. Removing one should not compromise the
performance of the model and might lead to a more parsimonious and
interpretable model. Third, some models can be crippled by predictors
with degenerate distributions.'' \footnote{Max Kuhn and Kjell Johnson,
  Applied Predictive Modeling, Springer Publishing, 2018}

Pearson's correlation coefficient: \begin{equation} 
\rho_{x,y} = \frac {E \left[(X - \mu_x)(X - \mu_y) \right]} {\sigma_x \sigma_y}
\end{equation}

\begin{equation} 
r_{xy} = \frac {\sum^n_{i=1} (x_i - \bar x)(y_1 - \bar y)} { {\sqrt {\sum^n_{i=1} (x_i - \bar x)^2 }} {\sqrt {\sum^n_{i=1} (y_i - \bar y)^2 }} }
\end{equation}

\includegraphics{02-eda_files/figure-latex/250-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c_m_corr_mat[}\StringTok{"T"}\NormalTok{, }\StringTok{"N"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7098085
\end{verbatim}

\textbf{No values in the correlation matrix meet the 0.75 cut off
criteria for problems.}

\hypertarget{boruta---dimensionality-reduction-transformed-data}{%
\subsubsection{Boruta - Dimensionality Reduction, TRANSFORMED
data}\label{boruta---dimensionality-reduction-transformed-data}}

\textbf{Perform Boruta search}

NOTE: \emph{mcAdj = TRUE}: If True, multiple comparisons will be
adjusted using the Bonferroni method to calculate p-values. Therefore,
\(p_i \leq \frac {\alpha} {m}\) where \(\alpha\) is the desired p-value
and \(m\) is the total number of null hypotheses.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1000}\NormalTok{)}
\KeywordTok{registerDoMC}\NormalTok{(}\DataTypeTok{cores =} \DecValTok{3}\NormalTok{) }\CommentTok{# Start multi-processor mode}
\NormalTok{start_time <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{() }\CommentTok{# Start timer}

\NormalTok{boruta_output <-}\StringTok{ }\KeywordTok{Boruta}\NormalTok{(Class }\OperatorTok{~}\StringTok{ }\NormalTok{.,}
                        \DataTypeTok{data =}\NormalTok{ c_m_class_}\DecValTok{20}\NormalTok{[, }\DecValTok{-1}\NormalTok{],}
                        \DataTypeTok{mcAdj =} \OtherTok{TRUE}\NormalTok{, }\CommentTok{# See Note above.}
                        \DataTypeTok{doTrace =} \DecValTok{1}\NormalTok{) }\CommentTok{# doTrace = 1, represents non-verbose mode.}

\KeywordTok{registerDoSEQ}\NormalTok{() }\CommentTok{# Stop multi-processor mode}
\NormalTok{end_time <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{() }\CommentTok{# End timer}
\NormalTok{end_time }\OperatorTok{-}\StringTok{ }\NormalTok{start_time }\CommentTok{# Display elapsed time}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 31.02332 secs
\end{verbatim}

\hypertarget{plot-variable-importance-transformed-data}{%
\subsubsection{Plot Variable Importance, TRANSFORMED
data}\label{plot-variable-importance-transformed-data}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(boruta_output,}
     \DataTypeTok{cex.axis =} \DecValTok{1}\NormalTok{,}
     \DataTypeTok{las =} \DecValTok{2}\NormalTok{,}
     \DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{5}\NormalTok{, }\DecValTok{50}\NormalTok{),}
     \DataTypeTok{main =} \StringTok{"Variable Importance, TRANSFORMED data(Bigger=Better)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-eda_files/figure-latex/254-1.pdf}

\hypertarget{variable-importance-scores-transformed-data}{%
\subsubsection{Variable Importance Scores, TRANSFORMED
data}\label{variable-importance-scores-transformed-data}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roughFixMod <-}\StringTok{ }\KeywordTok{TentativeRoughFix}\NormalTok{(boruta_output)}
\NormalTok{imps <-}\StringTok{ }\KeywordTok{attStats}\NormalTok{(roughFixMod)}
\NormalTok{imps2 <-}\StringTok{ }\NormalTok{imps[imps}\OperatorTok{$}\NormalTok{decision }\OperatorTok{!=}\StringTok{ "Rejected"}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"meanImp"}\NormalTok{, }\StringTok{"decision"}\NormalTok{)]}
\NormalTok{meanImps <-}\StringTok{ }\NormalTok{imps2[}\KeywordTok{order}\NormalTok{(}\OperatorTok{-}\NormalTok{imps2}\OperatorTok{$}\NormalTok{meanImp), ] }\CommentTok{# descending sort}

\KeywordTok{kable}\NormalTok{(meanImps) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|r|l}
\hline
  & meanImp & decision\\
\hline
R & 43.17613 & Confirmed\\
\hline
H & 34.30370 & Confirmed\\
\hline
P & 28.70674 & Confirmed\\
\hline
C & 27.72357 & Confirmed\\
\hline
K & 27.60838 & Confirmed\\
\hline
E & 26.18872 & Confirmed\\
\hline
Y & 22.84975 & Confirmed\\
\hline
T & 21.66359 & Confirmed\\
\hline
S & 21.44119 & Confirmed\\
\hline
A & 20.54316 & Confirmed\\
\hline
N & 20.10100 & Confirmed\\
\hline
V & 18.77068 & Confirmed\\
\hline
I & 18.69155 & Confirmed\\
\hline
F & 18.18632 & Confirmed\\
\hline
D & 17.64435 & Confirmed\\
\hline
G & 16.15207 & Confirmed\\
\hline
W & 15.77085 & Confirmed\\
\hline
L & 15.27614 & Confirmed\\
\hline
M & 14.83421 & Confirmed\\
\hline
Q & 14.12976 & Confirmed\\
\hline
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# knitr::kable(meanImps,}
\CommentTok{# full_width = F,}
\CommentTok{# position = "left",}
\CommentTok{# caption = "Mean Importance Scores & Decision, TRANSFORMED data")}
\end{Highlighting}
\end{Shaded}

The \emph{Boruta random forest test} shows that all features are
essential therefore none should be dropped from TRANSFORMED data.

\hypertarget{eda-conclusion}{%
\subsection{EDA Conclusion}\label{eda-conclusion}}

\hypertarget{feature-selection-extraction}{%
\subsubsection{Feature Selection \&
Extraction}\label{feature-selection-extraction}}

It was determined early on that three amino acids (C, F, I) from the
data amino acid percent compositions (c\_m\_RAW\_AAC.csv) had Skewness
greater than two. It was found that tranforming the features using the
square root function lowered the skewness to \{-0.102739 \(\leq\) skew
after transformation \(\leq\) 0.3478132\}.

Table 7.1, Skewness Before And After Square-Root Transform

\begin{longtable}[]{@{}lcc@{}}
\toprule
Amino Acid & Initial Skewness & Skew After Square-Root
Transform\tabularnewline
\midrule
\endhead
C, Cysteine & 2.538162 & 0.347813248\tabularnewline
F, Phenolalanine & 2.128118 & -0.102739748\tabularnewline
I, Isoleucine & 2.192145 & 0.293474879\tabularnewline
\bottomrule
\end{longtable}

The transformations of the three amino acids (C, F, I) did not
appriciably change the Correlation coefficient, R. Therefore no R values
were above 0.75 before or after testing. The highest coeffiecient of
correlation being Threonine and Argnine with an R of 0.7098. This
indicates that no features are collinear. Therefore the transformed data
is used throughout this experiment.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Information Block}

How to: Dimension Reduction using High Correlation

How to reduce features given high correlation (\textbar{}R\textbar{}
\textgreater{}= 0.75) \{-\}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Calculate the correlation matrix of the predictors.
\item
  If the correlation plot produced of any two variables is greater than
  or equal to (\textbar{}R\textbar{} \textgreater{}= 0.75), then we
  could consider feature elimination. This interesting heuristic
  approach would be used for determining which feature to
  eliminate.\footnote{Max Kuhn and Kjell Johnson, Applied Predictive
    Modeling, Springer Publishing, 2018,
    (\url{http://appliedpredictivemodeling.com/})}
\item
  Determine if the two predictors associated with the most significant
  absolute pairwise correlation (R \textgreater{}
  \textbar{}0.75\textbar{}), call them predictors A and B.
\item
  Determine the average correlation between A and the other variables.
  Do the same for predictor B.
\item
  If A has a more significant average correlation, remove it; otherwise,
  remove predictor B.
\item
  Repeat Steps 2--4 until no absolute correlations are above the
  threshold.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

An alternative test for variable importance carried out is called
Boruta. Boruta builds Random Forests then ``finds relevant features by
comparing original attributes' importance with importance achievable at
random.'' \footnote{\url{https://notabug.org/mbq/Boruta/}}

Boruta is used for dimensionality reduction of the
\textbf{c\_m\_Transformed data}. Bortua showed that all dependent
features are essential for the generation of a Random Forest Decision
Tree. It would wise to keep all features for that model test and
throughout the generation of other models. All features have decisive
mean importance, which is generated by a Gini calculation.

\end{document}
