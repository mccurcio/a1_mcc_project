<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Introduction | 01.20.2020.INTRO.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Introduction | 01.20.2020.INTRO.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Introduction | 01.20.2020.INTRO.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="abstract.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i><b>1</b> Abstract</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#the-epicycle-of-analysis"><i class="fa fa-check"></i><b>2.1</b> The Epicycle of Analysis</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#supervised-learning"><i class="fa fa-check"></i><b>2.2</b> Supervised Learning</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.3</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#big-challenges-in-machine-learning"><i class="fa fa-check"></i><b>2.3.1</b> 4 Big Challenges in Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#experimental-procedure"><i class="fa fa-check"></i><b>2.4</b> Experimental Procedure</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>2.4.1</b> Exploratory data Analysis (EDA)</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#caret-library-for-r"><i class="fa fa-check"></i><b>2.4.2</b> Caret library for R</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction.html"><a href="introduction.html#training-predictive-model"><i class="fa fa-check"></i><b>2.4.3</b> Training predictive model</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction.html"><a href="introduction.html#analysis-of-results"><i class="fa fa-check"></i><b>2.4.4</b> Analysis of results</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#big-challenges-in-machine-learning-ft.-martin-jaggi"><i class="fa fa-check"></i><b>2.5</b> 4 Big Challenges in Machine Learning (ft. Martin Jaggi)</a><ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#why-to-separate-training-data-set-and-test-data-set-for-validation"><i class="fa fa-check"></i><b>2.5.1</b> Why to separate training data set and test data set for validation?</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#probably-approximately-correct-learning-theory-by-leslie-valiant"><i class="fa fa-check"></i><b>2.6</b> “Probably approximately correct” learning theory by Leslie Valiant</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#over-fitting-and-model-tuning"><i class="fa fa-check"></i><b>2.7</b> Over-Fitting and Model Tuning</a></li>
<li class="chapter" data-level="2.8" data-path="introduction.html"><a href="introduction.html#choosing-between-models-see-p.78"><i class="fa fa-check"></i><b>2.8</b> Choosing Between Models, See P.78</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction" class="section level1">
<h1><span class="header-section-number">2</span> Introduction</h1>
<p>At the intersection between Applied Mathematics, Computer Science and an understanding of Biological Sciences is subset of knowledge known as Bioinformatics. Some find Bioinformatics and its more general title Data Science difficult to define. The most ubiquitous pictograph is indeed the intersection of three fields of study. Data Science is simply the overall title when more general domain knowledge is discussed. Other fields you may come across would be, the study of business or marketing begets Business Intelligence. The study of chemistry begets the field Chemoinformatics.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> <span class="math inline">\(^,\)</span> <a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Health or Healthcare begets the field Healthcare-Informatics.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<div class="figure">
<img src="../00-data/10-images/Bio-DS-Venn-diagram2-1024x576.png" alt="Venn Diagrams of Bioinformatics Vs Data Science" />
<p class="caption">Venn Diagrams of Bioinformatics Vs Data Science</p>
</div>
<p>What is Predictive Modeling?</p>
<p>The term ‘Predictive Modeling’ should bring to mind work in the computer science field also called Machine Learning (ML), Artificial Intelligence (AI), Data Mining, Knowledge discovery in databases (KDD), and possibly even encompassing Big Data as well.</p>
<blockquote>
<p>Indeed, these associations are appropriate and the methods implied by these terms are an integral piece of the predictive modeling process. But predictive modeling encompasses much more than the tools and techniques for uncovering patterns within data. The practice of predictive modeling defines the process of developing a model in a way that we can understand and quantify the model’s prediction accuracy on future, yet-to-be-seen data.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</blockquote>
<p>In the booklet entitled, ‘The Elements of Data Analytic Style’<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> there is an interesting checklist for the uninitiated into the realm of science report writing and indeed scientific thinking. A shorter more succinct listing of the steps, which I prefer, and is described by Roger Peng in his book, The Art Of Data Science. The book lists what he describes as the “Epicycle of Analysis.” <a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<div id="the-epicycle-of-analysis" class="section level2">
<h2><span class="header-section-number">2.1</span> The Epicycle of Analysis</h2>
<ol style="list-style-type: decimal">
<li>Stating and refining the question<br />
</li>
<li>Exploring the data<br />
</li>
<li>Building formal statistical models<br />
</li>
<li>Interpreting the results<br />
</li>
<li>Communicating the results</li>
</ol>
<p>Therefore let us start by posing a question;</p>
<ul>
<li>Is there a correlation between the data points which are outliers from principal component analysis (PCA) and 6 types of predictive modeling?</li>
</ul>
<p>This experiment is interested in determining if PCA would provide information on the false-positives and false-negatives that were an inevitable part of model building and optimization. The six predictive models that have chosen for this work are Logistic Regression, Support Vector Machines (SVM) (linear, polynomial, and radial basis function kernels), Random Forest and a Neural Network which uses Auto-encoding.</p>
<p>It is common for Data Scientists to test their data sets for feature importance and feature selection. One test that has interested this researcher is Principal component analysis. It can be an extremely useful tool. PCA is an unsupervised machine learning technique which “reduces data by geometrically projecting them onto lower dimensions called principal components (PCs), with the goal of finding the best summary of the data using a limited number of PCs.”<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> However, the results that it provides may not be immediately intuitive to the lay person.</p>
<p>How do the advantages and dis-advantages of using PCA compare with other machine learning techniques. The advantages are numerable and include dimensionality reduction, filtering out noise inherent in the data and it may preserve the global structure of the data. Does the global and graphical structure of the data produced by the first two principal components provide any insights into how the predictive models of Logistic Regression, Neural Networks utilizing auto-encoders, Support Vector Machines and Random Forest. In essence, is PCA sufficiently similar to any of the applied mathematics tools of more advanced approaches. Also, this work is to simply teach myself machine learning or predictive modeling techniques.</p>
<p>The data for this study was derived from the Uniprot database. From the Uniprot database was queried for two protein groups. The first group was Myoglobin and the second was a control group comprised of human proteins not related to Hemoglobin or Myoglobin. There have been a group of papers that are striving to classify types of proteins by their amino acid structure alone. The simplest classification procedures involve using the percent amino acid composition. This is calculated by using the count of a amino acid over the total number in that protein.</p>
<p>Percent Amino Acid Composition:</p>
<p><span class="math display">\[\%AAC_X ~=~ \frac{N_{Amino~Acid~X}}{Total ~ N ~ of ~ AA}\]</span></p>
<p>The experimental approach carried out Exploratory Data Analysis to determine if the features were skewed and needed to be transformed. In a random system where amino acids were chosen at random one would expect the percent amino acid composition to be close to 5%. However this is far from the case for the Myoglobin proteins or the control protein samples.</p>
<div class="figure">
<img src="../00-data/10-images/c_m_Mean_AAC.png" alt="Mean % Amino Acid Compositions for Control &amp; Myoglobin" />
<p class="caption">Mean % Amino Acid Compositions for Control &amp; Myoglobin</p>
</div>
<p>In general, there are four types of Predictive Modeling or machine learning approaches</p>
<ol style="list-style-type: decimal">
<li>Supervised,</li>
<li>Unsupervised,</li>
<li>Reinforcement,</li>
<li>Semi-Supervised.</li>
</ol>
<p>For the sake of this document only the first two approaches (Supervised &amp; Unsupervised learning) will be discussed.</p>
</div>
<div id="supervised-learning" class="section level2">
<h2><span class="header-section-number">2.2</span> Supervised Learning</h2>
<p>In supervised learning, data consists of observations <span class="math inline">\(X_i\)</span> (where <span class="math inline">\(X\)</span> may be a matrix of values) that also contains a corresponding label, <span class="math inline">\(y_i\)</span>. The label <span class="math inline">\(y\)</span> may be anyone of <span class="math inline">\(C\)</span> classes. In our case of a binary classifier, we have {‘Is myoglobin’, ‘Is control’}.</p>
<p>Data set: <span class="math inline">\((X_1, y_1), (X_2 , y_2), ~. . ., ~(X_N , y_N); ~~~y \in \{1, ..., ~C\}\)</span>, where <span class="math inline">\(C\)</span> is the number of classes</p>
<p>A machine learning algorithm determines a pattern from the input information and groups this with its necessary title or classification.</p>
<p>One example might be that we require a machine which separates red widgets from blue widgets. One predictive algorithm is called K-Nearest Neighbor (K-NN). K-NN looks at an unknown object and then proceeds to calculate the distance (most commonly the euclidean distance) to the <span class="math inline">\(K\)</span> nearest neighbors. If we consider the figure below and choose <span class="math inline">\(K\)</span> = 3, we would find a circumstance as shown. In the dark solid black on the K-Nearest-Neighbor figure we find that the green widget is nearest to two red widgets and one blue widget. In the voting K-NN algorithm (2 reds vs 1 blue) means that we would consign our unknown green object is most likely red.</p>
<p>In order for the K-NN algorithm to work the data most be complete with a set of features and a label of each item. Without the corresponding label a data scientist would need a different criteria to track the widgets.</p>
<p>Six of the seven algorithms that this report investigates are supervised. Logit, support vector machines, Random Forest and the neural network that I have chosen require labels for the classification process.</p>
<div class="figure">
<img src="../00-data/10-images/K-Nearest-Neighbor.png" alt="K-Nearest-Neighbor" />
<p class="caption">K-Nearest-Neighbor</p>
</div>
<div id="what-is-a-shallow-learner" class="section level4 unnumbered">
<h4>What is a shallow learner?</h4>
<p>Let us investigate the K-NN algorithm and figure a little further. If we change our value of <span class="math inline">\(K\)</span> to 5 then we see a different result. By using <span class="math inline">\(K = 5\)</span> we will now consider the out dashed-black line. This larger <span class="math inline">\(K\)</span> value contains three blue widgets and two red widgets. If we are now asked to vote our choice, we find that 3 blue beats the 2 red and we assign the unknown a BLUE widget. This assignment is the opposite of the inner circle.</p>
<p>If a researcher were to use K-NN then the algorithm would have to test many possible <span class="math inline">\(K\)</span> values and compare the results, then choose the <span class="math inline">\(K\)</span> with the highest accuracy. However, this is where K-NN falters. To use K-NN the computer algorithm needs to keep all data points it used for its initial training (accuracy testing). Any new unknowns could be conceivably tested against any or all the previous data points. The K-NN does use a generalized rule that would make future assignment quick on the contrary it must memorize all the points for the algorithm to work. K-NN cannot delete the points until it is complete. It is true that the algorithm is simple but not efficient. Matter and fact, as the number of feature dimensions increases this causes the complexity (also known as Big O) to rise. The complexity of K-NN is: <span class="math inline">\(O(K-NN) ~~\propto ~~nkd\)</span> .</p>
<p>Where <span class="math inline">\(n\)</span> is the number of observations, <span class="math inline">\(k\)</span> is the number of nearest neighbors it must check and d is the number of dimensions.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>Given that K-NN tends to ‘memorize’ its data to complete its task it is considered a lazy and a shallow learner. If we were to use a more generalized rule, such as <strong>{Blue</strong> for (<span class="math inline">\(x &lt;= 5\)</span>)<strong>}</strong> this would be more dynamic and deeper approach by comparison.</p>
</div>
<div id="what-is-deep-learning" class="section level4 unnumbered">
<h4>What is deep learning?</h4>
<p>By contrast a deep learning system is one that able to generalize information constructing multiple levels of representation or learning a hierarchy of features, …, one level at a time, using unsupervised feature learning to learn a new transformation at each level.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<p>Another much simpler definition states, “What is not a multi-layer neural network is not deep learning - Anonymous.”</p>
<p>????</p>
</div>
</div>
<div id="unsupervised-learning" class="section level2">
<h2><span class="header-section-number">2.3</span> Unsupervised Learning</h2>
<p>By contrast to the supervised learning system, unsupervised learning does not require a label for it to operate.</p>
<p>Data set: <span class="math inline">\((X_1), (X_2), ~. . ., ~(X_N)\)</span> where <span class="math inline">\(X\)</span> may represent a matrix (<span class="math inline">\(m\)</span> observations by <span class="math inline">\(n\)</span> features) of values.</p>
<p>Principal Component Analysis is an example of unsupervised learning, which we will discuss in more detail in chapter 3. The data despite or without its labels are transformed to provide a maximization of the variances in the dataset. Yet another objective of Unsupervised learning is to discover “interesting structures” <a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> in the data. There are several methods that structure may show itself these include clustering, knowledge discovery of latent variable or discovering graph structure. In many instances and as a subheading to the a fore mentioned points unsupervised learning is used for dimension reduction or feature selection.</p>
<p>Among the simplest unsupervised learning algorithms is K-means. K-means does not rely on the class labels of the dataset at all. In fact, K-means may be used to determine any number of classes despite any predetermined values. K-means can discover clusters which may then be used in classification or hierarchical feature representation. K-means has several alternative methods but in general calculates the distance (or conversely the similarity) of observations to a mean value of the <span class="math inline">\(K\)</span>th grouping. The mean value is called the center of mass, the Physics term that provides an excellent analogy since the center of mass is a weighted average. By choosing different number of groupings (values of <span class="math inline">\(K\)</span> much like the K-NN) then comparing the grouping by a measure of accuracy, one example being, mean square error.</p>
<div class="figure">
<img src="../00-data/10-images/k-means-2.png" alt="K-Means" />
<p class="caption">K-Means</p>
</div>
<p>It is easy to see through much or machine learning or predictive modeling if one understands bits of the inner workings of these algorithms,</p>
<div id="big-challenges-in-machine-learning" class="section level3">
<h3><span class="header-section-number">2.3.1</span> 4 Big Challenges in Machine Learning</h3>
<p><a href="https://www.youtube.com/watch?v=v3QGgtmAZTE&amp;t=0s&amp;index=10&amp;list=WL" class="uri">https://www.youtube.com/watch?v=v3QGgtmAZTE&amp;t=0s&amp;index=10&amp;list=WL</a></p>
<p><a href="https://www.machinelearning.ai/machine-learning/4-big-challenges-in-machine-learning-ft-martin-jaggi-2/" class="uri">https://www.machinelearning.ai/machine-learning/4-big-challenges-in-machine-learning-ft-martin-jaggi-2/</a></p>
<p>Supervised Vs Unsupervised</p>
<p>Problem 1: The vast majority of information in the world in unlabeled so it would be advantageous to have a good Unsupervised machine learning algorithms to use.</p>
<p>Problem 2: Algorithms are very specialized, too specific.</p>
<p>Problem 3: Transfer learning to new environments</p>
<p>Problem 4: Scale, the scale of information is huge in reality and we have computers that work in gigabytes not the Exabytes that humans may have available to them. The scale of distributed Big Data…</p>
</div>
</div>
<div id="experimental-procedure" class="section level2">
<h2><span class="header-section-number">2.4</span> Experimental Procedure</h2>
<p>The experimental procedure for this report is quite straightforward. The procedure will be broken into 3 major steps.</p>
<div id="exploratory-data-analysis-eda" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Exploratory data Analysis (EDA)</h3>
<p>During EDA the data was checked for irregularities, such as missing data, outliers among features, skewness, and visually for normality using QQ-plots. The only irregularity that posed a significant issue was the skewness of the amino acid features. Many of 20 amino acid features had a significant number of outliers as seen by Boxplot analysis, however only three features had skew which might have presented a problem. Dealing with the skew of the AA was important due to the fact that Principal Component Analysis was a major aspect of this experiment.</p>
<p>It was determined earlier that three amino acids (C, F, I) from the single amino acid percent composition should be transformed by using the square root function. The choice of transformations was Natural log, log base 10, squaring (<span class="math inline">\(x^2\)</span>) and using the reciprocal (<span class="math inline">\(1 / x\)</span>) of the values. The square root transformation lowered the skewness to values of less than {skew <span class="math inline">\(\leq\)</span> 1.0} from greater than 2 in all cases to {-0.102739 <span class="math inline">\(\leq\)</span> skew after transformation <span class="math inline">\(\leq\)</span> 0.3478132}.</p>
<table>
<thead>
<tr class="header">
<th align="left">Amino Acid</th>
<th align="center">Initial skewness</th>
<th align="center">Skew after square root transform</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C, Cysteine</td>
<td align="center">2.538162</td>
<td align="center">0.347813248</td>
</tr>
<tr class="even">
<td align="left">F, Phenolalanine</td>
<td align="center">2.128118</td>
<td align="center">-0.102739748</td>
</tr>
<tr class="odd">
<td align="left">I, Isoleucine</td>
<td align="center">2.192145</td>
<td align="center">0.293474879</td>
</tr>
</tbody>
</table>
<p>Once the three features were transformed this dataset was denoted <code>~/00-data/02-aac_dpc_values/c_m_TRANSFORMED.csv</code> and used throughout the rest of the analysis.</p>
<p>It was decided early in the work that R<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>, RStudio<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> and its machine learning library / framework <code>caret</code><a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> would be used</p>
</div>
<div id="caret-library-for-r" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Caret library for R</h3>
<div id="data-partitioning" class="section level4">
<h4><span class="header-section-number">2.4.2.1</span> Data Partitioning</h4>
<p>The R/caret library is attractive to use for many reasons. It currently allows some 238<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> machine learning models which have been written using disparate options and data structures. The utility of caret is that it organizes the input and output into a common format making the need for learning only one grammar and syntax. Other functions, used in this work, built into caret is a data partitioning subroutine. The partitioning is carried out such that it attempts to avoid imbalanced data. In short, the program balances the number of positive samples to negative samples, etc. Within this experiment data partitioning was set to 80 parts for training versus 20 parts for testing.</p>
<pre><code># Partition data into training and testing sets
set.seed(1000)
index &lt;- createDataPartition(c_m_TRANSFORMED.csv$Class, p = 0.8, list = FALSE)

training_set.2 &lt;- c_m_9aa[ index, ]
test_set.2     &lt;- c_m_9aa[-index, ]</code></pre>
</div>
<div id="training-the-predictive-model" class="section level4">
<h4><span class="header-section-number">2.4.2.2</span> Training the Predictive model</h4>
<p>The training section</p>
<pre><code>## Training caret-R code
set.seed(1000)

## Create model, 10 fold cross validation repeated 5X
fitControl &lt;- trainControl(method = &quot;repeatedcv&quot;, 
                           number = 10,
                           repeats = 5,
                           savePredictions = &quot;final&quot;)
                           
## Grid exploration
grid = expand.grid(C = seq(0.5, 10, 0.5))

## Train command
model_object &lt;- train(Class ~ .,
                      data = training_set,
                      trControl = fitControl,
                      method = &quot;svmLinear&quot;,
                      tune.Grid = grid)</code></pre>
<p>Procedure:</p>
<ol start="6" style="list-style-type: decimal">
<li>Using Testing data set Predict classes and generate CM.</li>
<li>Compile CM output (Accuracy, MCC, etc.) for comparing 10 models.</li>
</ol>
</div>
</div>
<div id="training-predictive-model" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Training predictive model</h3>
</div>
<div id="analysis-of-results" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Analysis of results</h3>
<p>error / loss; sometime aka cost function taken from business</p>
<ol style="list-style-type: decimal">
<li>infer / predict</li>
<li>error / loss; sometime aka cost function taken from business</li>
<li>train / learn</li>
</ol>
<hr />
<ul>
<li>Data mining is all about extracting patterns from an organization’s stored data. These patterns can be used to gain insight into aspects of the organization’s operations, and to predict outcomes for future situations as an aid to decision-making.</li>
</ul>
<hr />
<ul>
<li><p>The fundamental goal of machine learning is to generalize beyond the examples in the training set.</p></li>
<li><p>No matter how much data we have, it is very unlikely that we will see those exact examples again at test time.</p></li>
<li><p>Doing well on the training set is easy (just memorize the examples).</p></li>
<li><p>The most common mistake among machine learning beginners is to test on the training data and have the illusion of success. If the chosen classifier is then tested on new data, it is often no better than random guessing.</p></li>
<li>HOLD back some data for more testing</li>
<li><p>if you hire someone to build a classifier, be sure to keep some of the data to yourself and test the classifier they give you on it.</p></li>
<li><p>cross-validation; this is very important</p></li>
</ul>
<hr />
</div>
</div>
<div id="big-challenges-in-machine-learning-ft.-martin-jaggi" class="section level2">
<h2><span class="header-section-number">2.5</span> 4 Big Challenges in Machine Learning (ft. Martin Jaggi)</h2>
<p><a href="https://www.youtube.com/watch?v=v3QGgtmAZTE&amp;t=0s&amp;index=10&amp;list=WL" class="uri">https://www.youtube.com/watch?v=v3QGgtmAZTE&amp;t=0s&amp;index=10&amp;list=WL</a></p>
<p><a href="https://www.machinelearning.ai/machine-learning/4-big-challenges-in-machine-learning-ft-martin-jaggi-2/" class="uri">https://www.machinelearning.ai/machine-learning/4-big-challenges-in-machine-learning-ft-martin-jaggi-2/</a></p>
<p>Supervised Vs Unsupervised</p>
<p>Problem 1: The vast majority of information in the world in unlabeled so it would be advantageous to have a good Unsupervised machine learning algorithms to use.</p>
<p>Problem 2: Algorithms are very specialized, too specific.</p>
<p>Problem 3: Transfer learning to new environments</p>
<p>Problem 4: Scale, the scale of information is huge in reality and we have computers that work in gigabytes not the Exabytes that humans may have available to them. The scale of distributed Big Data…</p>
<div id="why-to-separate-training-data-set-and-test-data-set-for-validation" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Why to separate training data set and test data set for validation?</h3>
<p>Q. How do you get better at formulating questions to ask your AI?
A. Big data</p>
</div>
</div>
<div id="probably-approximately-correct-learning-theory-by-leslie-valiant" class="section level2">
<h2><span class="header-section-number">2.6</span> “Probably approximately correct” learning theory by Leslie Valiant</h2>
<ul>
<li><p>Requirements of Learning: Cannot expect a learner to learn a concept exactly. There are only a small fraction of examples that describe our available instance/experimental space. It may be very difficult to describe the entire space with a small set.</p></li>
<li><p>Cannot always expect to learn a close approximation to the target concept, the training set will not be representative of your model. It will may/contain uncommon examples.</p></li>
<li><p>The only realistic expectation of a good learner is that with high probability it will learn a close approximation to the target concept/model.</p></li>
<li><p>The only reason we can hope for this is the <em>consistent distribution assumption</em>.</p></li>
</ul>
<hr />
<p>OVERFITTING HAS MANY FACES</p>
<ul>
<li>Bias and Variance</li>
<li>One way to understand over-fitting is by decomposing generalization error into bias and variance. Bias is a learner’s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things irrespective of the real signal.</li>
</ul>
<hr />
<ol start="9" style="list-style-type: decimal">
<li>Why to separate training data set and test data set for validation?</li>
</ol>
<hr />
<p><strong>Excellent description of splitting, p.160</strong></p>
<hr />
</div>
<div id="over-fitting-and-model-tuning" class="section level2">
<h2><span class="header-section-number">2.7</span> Over-Fitting and Model Tuning</h2>
</div>
<div id="choosing-between-models-see-p.78" class="section level2">
<h2><span class="header-section-number">2.8</span> Choosing Between Models, See P.78</h2>
<p>Measuring Performance in Classification Models</p>
<hr />
<p>Parameters vs. Hyperparameters</p>
<ul>
<li>A hyperparameter is a property of a learning algorithm, usually (but not always) having a numerical value. That value influences the way the algorithm works. Hyperparameters aren’t learned by the algorithm itself from data. They have to be set by the data analyst before running the algorithm.</li>
</ul>
<hr />
<p>[Top 10 Algos in DM]</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=_PwhiWxHK8o&amp;t=15s">Patrick Winston</a></li>
<li>The “soft margin” idea is aimed at extending the SVM algorithm</li>
<li><a href="https://www.youtube.com/watch?v=hCOIMkcsm_g">Andrew Ng</a></li>
</ul>
<hr />
<ul>
<li><p>Model evaluation</p></li>
<li><p>Some widely used model evaluation parameters for classification models (including cross validation) are as follows:</p></li>
<li><p>Confusion matrix (accuracy, precision, recall, and F1-score)</p></li>
</ul>
</div>
</div>



















<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="https://www.acs.org/content/acs/en/careers/college-to-career/chemistry-careers/cheminformatics.html" class="uri">https://www.acs.org/content/acs/en/careers/college-to-career/chemistry-careers/cheminformatics.html</a><a href="introduction.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="https://jcheminf.biomedcentral.com/" class="uri">https://jcheminf.biomedcentral.com/</a><a href="introduction.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><a href="https://www.usnews.com/education/best-graduate-schools/articles/2014/03/26/consider-pursuing-a-career-in-health-informatics" class="uri">https://www.usnews.com/education/best-graduate-schools/articles/2014/03/26/consider-pursuing-a-career-in-health-informatics</a><a href="introduction.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Max Kuhn, Kjell Johnson, Applied Predictive Modeling, Springer, <a href="ISBN:978-1-4614-6848-6" class="uri">ISBN:978-1-4614-6848-6</a>, 2013<a href="introduction.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>Jeff Leek, The Elements of Data Analytic Style, A guide for people who want to analyze data., Leanpub Books, <a href="http://leanpub.com/datastyle" class="uri">http://leanpub.com/datastyle</a>, 2015<a href="introduction.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Roger D. Peng and Elizabeth Matsui, The Art of Data Science, A Guide for Anyone Who Works with Data, Leanpub Books, <a href="http://leanpub.com/artofdatascience" class="uri">http://leanpub.com/artofdatascience</a>, 2015<a href="introduction.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>Jake Lever, Martin Krzywinski, Naomi Altman, Principal component analysis, NATURE METHODS, VOL.14 NO.7, JULY 2017, 641-2<a href="introduction.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Olga Veksler, Machine Learning in Computer Vision, <a href="http://www.csd.uwo.ca/courses/CS9840a/Lecture2_knn.pdf" class="uri">http://www.csd.uwo.ca/courses/CS9840a/Lecture2_knn.pdf</a><a href="introduction.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>Yoshua Bengio, Aaron Courville, and Pascal Vincent, Representation Learning: A Review and New Perspectives, arXiv:1206.5538v3, 23 Apr 2014<a href="introduction.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>Kevin P. Murphy, Machine learning : a probabilistic perspective, 2012, <a href="ISBN:978-0-262-01802-9" class="uri">ISBN:978-0-262-01802-9</a><a href="introduction.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p><a href="https://cran.r-project.org/" class="uri">https://cran.r-project.org/</a><a href="introduction.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p><a href="https://rstudio.com/" class="uri">https://rstudio.com/</a><a href="introduction.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p><a href="http://topepo.github.io/caret/index.html" class="uri">http://topepo.github.io/caret/index.html</a><a href="introduction.html#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p><a href="http://topepo.github.io/caret/available-models.html" class="uri">http://topepo.github.io/caret/available-models.html</a><a href="introduction.html#fnref14" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="abstract.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
